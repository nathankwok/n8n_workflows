{"updatedAt":"2025-11-15T21:31:17.000Z","createdAt":"2025-10-07T07:32:02.973Z","id":"1X4HfF4Rou9pBt19","name":"ask-data_Omni_Dashboard_Search_Validator","active":false,"isArchived":false,"nodes":[{"parameters":{"httpMethod":"POST","path":"b1af5244-90e6-44eb-ac3f-87b96108ec6b","authentication":"basicAuth","options":{"responseHeaders":{"entries":[{"name":"Content-Type","value":"application/json"}]}}},"type":"n8n-nodes-base.webhook","typeVersion":2.1,"position":[176,1488],"id":"b4182de2-29e7-45c8-89e0-cab5f649f954","name":"Webhook","webhookId":"b1af5244-90e6-44eb-ac3f-87b96108ec6b","alwaysOutputData":true,"credentials":{"httpBasicAuth":{"id":"3AVUqEU99hkVKUOW","name":"Zapier Inbound Basic Auth Webhook"}}},{"parameters":{"promptType":"define","text":"=<task>\n1. Go through the input list of documents to filter out ones that have a false boolean value for `has_dashboard` . \n2. Extract out the fields from each output.\n  - Use the document_id to craft a dashboard_url `https://cribl.omniapp.co/dashboards/{document_id}` \n  - Use the folder_path to craft a folder_url like `https://cribl.omniapp.co/f/{folder_path}`\n  - If the folder_path has white-space in between, replace the whitespace with a dash (`-`). For example if the folder_path is `gtm leads`, then the modified folder_path is `gtm-leads` and the folder_url becomes `https://cribl.omniapp.co/f/gtm-leads`\n3. Then craft a well formatted slack_message in the tone of a helpful data analyst, using each output document, keeping in mind everything in the slack_message_format .\n4. Finally, output in a structured JSON output format with the following keys:\n- message\n- document_ids (in descending order by document count)\n- folder_urls\n</task>\n\n<input>\n```json\n{{ $('Map Reduce Document Counts').first().json.output.toJsonString() }}\n```\n</input>\n\n<guidelines>\n\n<picking_and_ordering_documents>\nYou should pick documents that match these criteria, in no particular order.\n- The document's name should not have \"[WIP]\" in its name.\n- The chosen list of documents should be ordered in descending order by document count.\n- The chosen list of documents should be limited to the top 3 documents by count, after having filtered out documents that do not meet other criteria.\n</picking_and_ordering_documents>\n\n\n<slack_message_format>\nThe message should:\n  - tag the user's username, which is `{{ $('Global Vars').first().json.body.message_user_name }}`. \n  - address their original request, which was `{{ $('Global Vars').first().json.body.message_text }}`.\n  - should not write word-for-word their original request but instead should extract key words from their request to use to summarize what their original request might be related to.\n  - say that these dashboards might contain what they need.\n  - should list out documents after addressing them.\n  - Each document in the slack message should include the {document_name} that is linked to the respective {dashboard_url} and that the document exists in the {folder_name}, which is also linked to the respective {folder_url}.\n  - should not include any notes about helping further.\n  - should limit the number of documents to the top 3 documents by count.\n  - **CRITICAL**: should order the list of documents in descending order by the count value, but the count should not be in the message itself.\n</slack_message_format>\n\n</guidelines>\n\n\n<output_format>\nThe resulting output JSON should be like this:\n```json\n{\n  \"message\": \"formatted slack message\",\n  \"document_ids\": [\n    \"document_id_1\",\n    \"document_id_2\"\n  ],\n  \"folder_urls\": [\n    \"folder_url_1\",\n    \"folder_url_2\"\n  ]\n}\n</output_format>","hasOutputParser":true,"needsFallback":true,"options":{"systemMessage":"You are an expert data analyst who is well versed with the dashboards you have built in Omni Analytics Business Intelligence tool. You triage requests from company stakeholders who want to find relevant dashboards in the Omni BI tool."}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":2.2,"position":[8800,2544],"id":"140ac7f1-db4d-45ed-9ff6-ac56777c764f","name":"Response Agent","alwaysOutputData":false,"retryOnFail":true,"waitBetweenTries":250,"onError":"continueErrorOutput"},{"parameters":{"model":"o4-mini","options":{"responseFormat":"json_object"}},"type":"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi","typeVersion":1,"position":[8672,2768],"id":"8af46757-8333-4f52-b4a4-deb073624991","name":"Response Agent o4-mini","credentials":{"azureOpenAiApi":{"id":"N96DE6AiByL8h8kA","name":"Azure Open AI o4-mini"}}},{"parameters":{"modelName":"models/gemini-2.5-pro","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[8848,2816],"id":"37cf9178-6ba5-443a-bde7-58be8e03ad64","name":"Response Agent Gemini 2.5 Pro","credentials":{"googlePalmApi":{"id":"LKQbGwmroZKBfciU","name":"Gemini - Cribl"}}},{"parameters":{"schemaType":"manual","inputSchema":"{\n\t\"type\": \"object\",\n\t\"properties\": {\n      \"message\": {\n        \"type\": \"string\"\n      },\n      \"document_ids\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"string\"\n        }\n      },\n      \"folder_urls\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"string\"\n        }\n      }\n\t}\n}"},"type":"@n8n/n8n-nodes-langchain.outputParserStructured","typeVersion":1.3,"position":[9056,2784],"id":"7f7760aa-340a-420c-9b6d-cb0aad825c40","name":"Response Agent Structured Output Parser","notesInFlow":true,"notes":"Success path"},{"parameters":{"schemaType":"manual","inputSchema":"{\n\t\"type\": \"array\"\t\n}"},"type":"@n8n/n8n-nodes-langchain.outputParserStructured","typeVersion":1.3,"position":[9072,2976],"id":"680219b5-1237-41eb-8fdb-fa4d713b3e2c","name":"Response Agent Structured Output Parser1","notesInFlow":true,"notes":"Error path"},{"parameters":{"content":"## Respond with recommendations via Slack\n","height":656,"width":720,"color":5},"type":"n8n-nodes-base.stickyNote","position":[8576,2336],"typeVersion":1,"id":"94a6636b-d5c3-45e8-8376-61afca1cf4b4","name":"Sticky Note"},{"parameters":{"method":"POST","url":"={{ $('Global Vars').first().json.zapier_slack_response_webhook.webhook_url }}","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={\n  \"output\": {{ $('Response Agent').first().json.output.toJsonString() }},\n  \"body\": {{ $('Global Vars').first().json.body.toJsonString() }},\n  \"message\": {{ $('Response Agent').first().json.output.message.toJsonString() }}\n}","options":{}},"type":"n8n-nodes-base.httpRequest","typeVersion":4.2,"position":[9504,1792],"id":"28704e27-d064-4e69-9d31-904628ee260e","name":"Send Slack Success Message","alwaysOutputData":false,"onError":"continueRegularOutput"},{"parameters":{"content":"# Top down\n- extract key words from message\n- use key words to search similarly named document names\n- using document_ids, find their associated document query names\n  - validate that the query names are similar to key words and to the message\n\n- using document_ids, find their associated document query filters\n  - validate that list of document query filters are similar to key words and to the message\n\n- do for every document \n","height":368,"width":656},"type":"n8n-nodes-base.stickyNote","position":[-1616,-704],"typeVersion":1,"id":"009173cd-c7aa-41ca-b5af-64eb73b2c131","name":"Sticky Note2"},{"parameters":{"content":"# Bottoms Up\n- extract key words from message\n- use key words to search similarly named document query filters\n- get the list of document query filters and find the document queries associated with them\n  - validate that the query names are similar to key words and to the message\n\n- from the list of document query filters, get their associated documents\n  - validate that list of document names are similar to key words and to the message\n\n\n","height":368,"width":656},"type":"n8n-nodes-base.stickyNote","position":[-896,-704],"typeVersion":1,"id":"cb4d8dba-6638-44fc-8f3a-bb16861f61ea","name":"Sticky Note3"},{"parameters":{"content":"# ask-data questions\nhttps://cribl.slack.com/archives/C02GRDZS7QF/p1758010156612549\n\nhttps://cribl.slack.com/archives/C02GRDZS7QF/p1758008040422269\n\nhttps://cribl.slack.com/archives/C02GRDZS7QF/p1757955122490669\n\nhttps://cribl.slack.com/archives/C02GRDZS7QF/p1758039148424459\n\nhttps://cribl.slack.com/archives/C02GRDZS7QF/p1758036683995729\n\n","height":352,"width":784},"type":"n8n-nodes-base.stickyNote","position":[-1456,-1136],"typeVersion":1,"id":"ba3d5f95-2d1e-4ea1-a922-e747dac454a3","name":"Sticky Note4"},{"parameters":{"content":"## Features\n- filter by user who emoji'ed?\nalec U050E77CEQP\nnathan U06PVBEK9T6\npriya U02CBV3GSM9\nlaura U0544ACG6SV\nmatt U073M1QH10R\nrebecca U099VNZAC3D\njerome U07KD0478CQ\n\nhttps://www.productcompass.pm/p/n8n-mcp-servers-uv\n\n\n\n- filter dashboards by what dashboards person has access to\n","height":240,"width":304},"type":"n8n-nodes-base.stickyNote","position":[-544,-1120],"typeVersion":1,"id":"1faf44ac-5c72-4041-b0e6-5da3cb25f937","name":"Sticky Note5"},{"parameters":{"content":"# Infra Cleanup\n\n/home/nathankwok/n8n_deployment contains the working dir of n8n\n\nget rid of /home/nathankwok/n8n_deployment/temp_deployment_copy . its just a copy of the working dir\n\n/home/nathankwok/n8n_deployment/temp_deploy.sh tries to deploy with references to the temp_deployment_copy dir\n\ncheck is deploy-n8n-supabase.sh also references temp dir\n\n\n","height":368,"width":640},"type":"n8n-nodes-base.stickyNote","position":[-2320,-704],"typeVersion":1,"id":"3b5d7b21-4669-4e44-90fb-032d690d953c","name":"Sticky Note6"},{"parameters":{"promptType":"define","text":"=You are given lists of objects with objects representing:\n- documents\n\n\n<task>\n1. Extract out only the document data into a list, with all keys only from the document_structure schema. There will potentially be duplicate document objects in this list.\n2. Map-reduce the resulting documents by deduplicating the same documents (by document_id) but keeping count of documents with the same id before deduplicating. The count should be an additional key in each document object with each document being unique by the document_id\n3. Output the list of document objects with counts with each object in the schema like map_reduce_count_document_structure .\n</task>\n\n\n<document_structure>\n```json\n{\n\"document_id\": \"959cb1c9\",\n\"owner_name\": \"John McGuire\",\n\"owner_id\": \"86a545a6-5958-43e5-8f16-68eb9f148744\",\n\"document_scope\": \"organization\",\n\"document_name\": \"Team: SDR Manager\",\n\"folder_name\": \"Marketing\",\n\"folder_id\": \"3089bcee-baea-45af-8613-63077f0e9417\",\n\"has_dashboard\": true,\n\"folder_path\": \"marketing\"\n}\n```\n</document_structure>\n\n\n<map_reduce_count_document_structure>\n```json\n{\n\"document_id\": \"959cb1c9\",\n\"owner_name\": \"John McGuire\",\n\"owner_id\": \"86a545a6-5958-43e5-8f16-68eb9f148744\",\n\"document_scope\": \"organization\",\n\"document_name\": \"Team: SDR Manager\",\n\"folder_name\": \"Marketing\",\n\"folder_id\": \"3089bcee-baea-45af-8613-63077f0e9417\",\n\"has_dashboard\": true,\n\"folder_path\": \"marketing\",\n\"count\": 3\n}\n```\n</map_reduce_count_document_structure>\n\n\n<input_documents>\n{{ $input.first().json.output.toJsonString() }}\n</input_documents>\n\n\n<output_format>\nThe output must be a list of map_reduce_count_document_structure.\nExample:\n```json\n[\n  {\n    \"document_id\": \"959cb1c9\",\n    \"owner_name\": \"John McGuire\",\n    \"owner_id\": \"86a545a6-5958-43e5-8f16-68eb9f148744\",\n    \"document_scope\": \"organization\",\n    \"document_name\": \"Team: SDR Manager\",\n    \"folder_name\": \"Marketing\",\n    \"folder_id\": \"3089bcee-baea-45af-8613-63077f0e9417\",\n    \"has_dashboard\": true,\n    \"folder_path\": \"marketing\",\n    \"count\": 3\n  }\n]\n```\n</output_format>","hasOutputParser":true,"needsFallback":true,"options":{"systemMessage":"<role>\nYou are an expert data analyst, well versed in working with data and common data analysis algorithms, particularly with Map Reduce algorithm.\n</role>"}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":2.2,"position":[8096,2784],"id":"3d42414a-b81b-43c6-a8b2-dad0a72d8d78","name":"Map Reduce Document Count","alwaysOutputData":true,"notesInFlow":true,"retryOnFail":true,"waitBetweenTries":250,"disabled":true,"onError":"continueRegularOutput","notes":"Documents with more counts are weighted higher"},{"parameters":{"content":"Documents with more counts are weighted higher","height":96,"width":150,"color":6},"type":"n8n-nodes-base.stickyNote","position":[7616,2752],"typeVersion":1,"id":"20a842dd-e9ee-4f96-93e2-625d926537ed","name":"Sticky Note8"},{"parameters":{"numberInputs":6},"type":"n8n-nodes-base.merge","typeVersion":3.2,"position":[5264,2480],"id":"a59568a4-4ee3-490e-821d-a38a96fd2767","name":"Merge1","onError":"continueRegularOutput"},{"parameters":{"content":"### Cortex Search Query by Topic\n- searches For document queries\n- uses query_name and query_table that are similar to the topic"},"type":"n8n-nodes-base.stickyNote","position":[3664,3232],"typeVersion":1,"id":"7838c199-080b-4b12-81fd-3a7e4695704b","name":"Sticky Note9"},{"parameters":{"content":"### Cortex Search Document by Topic\n- searches For documents\n- uses document name that is similar to the topic"},"type":"n8n-nodes-base.stickyNote","position":[3600,2352],"typeVersion":1,"id":"01ebbddb-79f3-498b-b002-816f9331e266","name":"Sticky Note10"},{"parameters":{"content":"You are given lists of objects with objects representing:\n- documents\n- enriched document queries\n\n\n<task>\n1. Aggregate the list of documents and document_queries\n2. Extract out only the document data into a list, with all keys only from the document_structure schema. There will potentially be duplicate document objects in this list.\n3. Map-reduce the resulting documents by deduplicating the same documents (by document_id) but keeping count of documents with the same id before deduplicating. The count should be an additional key in each document object with each document being unique by the document_id\n3. Output the list of document objects with counts with each object in the schema like map_reduce_count_document_structure .\n</task>\n\n\n<enriched_document_query_structure>\n```json\n{\n  \"document_id\": \"45d06a29\",\n  \"query_id\": \"b3fe0946-15c0-4ea5-a6ff-fd8f23ac5964\",\n  \"query_table\": \"engineering__azure_cloud_cost\",\n  \"document_scope\": \"organization\",\n  \"query_name\": \"Monthly Costs by Usage\",\n  \"owner_name\": \"John McGuire\",\n  \"owner_id\": \"86a545a6-5958-43e5-8f16-68eb9f148744\",\n  \"document_name\": \"Team: Infrastructure Costs\",\n  \"folder_name\": \"Engineering\",\n  \"folder_id\": \"3089bcee-baea-45af-8613-63077f0e9417\",\n  \"has_dashboard\": true,\n  \"folder_path\": \"engineering\"\n}\n```\n</enriched_document_query_structure>\n\n\n<document_structure>\n```json\n{\n\"document_id\": \"959cb1c9\",\n\"owner_name\": \"John McGuire\",\n\"owner_id\": \"86a545a6-5958-43e5-8f16-68eb9f148744\",\n\"document_scope\": \"organization\",\n\"document_name\": \"Team: SDR Manager\",\n\"folder_name\": \"Marketing\",\n\"folder_id\": \"3089bcee-baea-45af-8613-63077f0e9417\",\n\"has_dashboard\": true,\n\"folder_path\": \"marketing\"\n}\n```\n</document_structure>\n\n\n<map_reduce_count_document_structure>\n```json\n{\n\"document_id\": \"959cb1c9\",\n\"owner_name\": \"John McGuire\",\n\"owner_id\": \"86a545a6-5958-43e5-8f16-68eb9f148744\",\n\"document_scope\": \"organization\",\n\"document_name\": \"Team: SDR Manager\",\n\"folder_name\": \"Marketing\",\n\"folder_id\": \"3089bcee-baea-45af-8613-63077f0e9417\",\n\"has_dashboard\": true,\n\"folder_path\": \"marketing\",\n\"count\": 3\n}\n```\n</map_reduce_count_document_structure>\n\n\n<input_enriched_document_queries>\n{{ $('Enrich Document Queries').item.json.output.toJsonString() }}\n</input_enriched_document_queries>\n\n\n<input_documents>\n{{ $('Cortex Search Document by Topic').item.json.output.toJsonString() }}\n</input_documents>\n\n\n<output_format>\nThe output must be a list of map_reduce_count_document_structure.\nExample:\n```json\n[\n  {\n    \"document_id\": \"959cb1c9\",\n    \"owner_name\": \"John McGuire\",\n    \"owner_id\": \"86a545a6-5958-43e5-8f16-68eb9f148744\",\n    \"document_scope\": \"organization\",\n    \"document_name\": \"Team: SDR Manager\",\n    \"folder_name\": \"Marketing\",\n    \"folder_id\": \"3089bcee-baea-45af-8613-63077f0e9417\",\n    \"has_dashboard\": true,\n    \"folder_path\": \"marketing\",\n    \"count\": 3\n  }\n]\n```\n</output_format>"},"type":"n8n-nodes-base.stickyNote","position":[8080,2352],"typeVersion":1,"id":"27c85c93-ffb0-4e59-b69b-e89605a01398","name":"Sticky Note12"},{"parameters":{"content":"## Semantic Search by Omni Picked Topic","height":880,"width":1376,"color":5},"type":"n8n-nodes-base.stickyNote","position":[2736,2368],"typeVersion":1,"id":"db789016-ce98-4af3-b9e1-ab3a46642b4d","name":"Sticky Note16"},{"parameters":{"operation":"executeQuery","query":"WITH ids AS (\n  SELECT\n    f.index AS ord,\n    f.value::VARCHAR AS doc_id\n  FROM LATERAL FLATTEN(\n    input => ARRAY_CONSTRUCT({{ $json.document_ids.map(item => `'${item}'`).join(', ') }})  -- duplicates allowed\n  ) f\n)\nSELECT \n\n  identifier as \"document_id\",\n  name as \"document_name\",\n  folder_id as \"folder_id\",\n  folder_name as \"folder_name\",\n  scope as \"document_scope\",\n  owner_name as \"owner_name\",\n  owner_id as \"owner_id\",\n  has_dashboard as \"has_dashboard\"\nfrom ids i\nJOIN {{ $('Global Vars').first().json.snowflake_tables.omni_documents.table_name }} d\n  ON d.identifier = i.doc_id"},"type":"n8n-nodes-base.snowflake","typeVersion":1,"position":[7616,2544],"id":"a85de574-be5f-4afa-b296-d97a368584e7","name":"Get Documents with Duplicates (multiple output)","credentials":{"snowflake":{"id":"C9vmzM7wtMKbWSDI","name":"Snowflake TRANSFORM"}},"onError":"continueRegularOutput"},{"parameters":{"aggregate":"aggregateAllItemData","destinationFieldName":"output","options":{}},"type":"n8n-nodes-base.aggregate","typeVersion":1,"position":[7872,2544],"id":"848e2896-a718-4ae7-968f-6a689ff0e772","name":"Aggregate Documents","onError":"continueRegularOutput"},{"parameters":{"modelName":"models/gemini-2.5-pro","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[8144,3056],"id":"bb8cbadb-f9d8-4928-bd4a-4bd598ac4ab9","name":"Map Reduce Agent Gemini 2.5 Pro","credentials":{"googlePalmApi":{"id":"LKQbGwmroZKBfciU","name":"Gemini - Cribl"}},"disabled":true},{"parameters":{"content":"```\n[\n  {\n    \"body\": {\n      \"channel_id\": \"C08AVACNUER\",\n      \"channel_name\": \"data-eng-test-channel\",\n      \"conversation_id\": \"C08AVACNUER\",\n      \"event_id\": \"1758674436.000760\",\n      \"event_timestamp\": \"2025-09-24T00:40:36.000Z\",\n      \"is_message_user_bot\": \"False\",\n      \"message_text\": \"customer breakdown\",\n      \"message_timestamp\": \"2025-09-24T00:39:00.400Z\",\n      \"message_ts\": \"1758674340.400329\",\n      \"message_user_email\": \"ataggart@cribl.io\",\n      \"message_user_first_name\": \"Alec\",\n      \"message_user_id\": \"U050E77CEQP\",\n      \"message_user_last_name\": \"Taggart\",\n      \"message_user_name\": \"alec_taggart\",\n      \"reaction\": \"eyes\",\n      \"reaction_user_email\": \"nkwok@cribl.io\",\n      \"reaction_user_id\": \"U06PVBEK9T6\",\n      \"team_domain\": \"cribl\",\n      \"team_id\": \"T3XQYAF26\"\n    },\n    \"snowflake_base_url\": \"https://ml16699-hya89079.snowflakecomputing.com\",\n    \"omni_documents_search_service\": {\n      \"snowflake_database\": \"ANALYTICS\",\n      \"snowflake_schema\": \"OMNI\",\n      \"service_name\": \"omni_documents_search_service\"\n    },\n    \"omni_document_queries_query_table_search_service\": {\n      \"snowflake_database\": \"ANALYTICS\",\n      \"snowflake_schema\": \"OMNI\",\n      \"agent_name\": \"omni_document_queries_query_table_search_service\"\n    },\n    \"omni_document_queries_query_name_search_service\": {\n      \"snowflake_database\": \"ANALYTICS\",\n      \"snowflake_schema\": \"OMNI\",\n      \"agent_name\": \"omni_document_queries_query_name_search_service\"\n    },\n    \"omni_documents_analyst_agent\": {\n      \"snowflake_database\": \"SNOWFLAKE_INTELLIGENCE\",\n      \"snowflake_schema\": \"AGENTS\",\n      \"agent_name\": \"OMNI_DOCUMENTS_ANALYST_AGENT\"\n    },\n    \"zapier_slack_response_webhook\": {\n      \"webhook_url\": \"https://hooks.zapier.com/hooks/catch/23046078/u1mp0gx/\"\n    },\n    \"slack\": {\n      \"error_message\": \"The Omni agent could not find relevant dashboards :cry:\"\n    },\n    \"omni\": {\n      \"omni_base_url\": \"https://cribl.omniapp.co\",\n      \"model_id\": \"4345b118-cbbe-4f7c-a705-ea0aa8da57c0\"\n    }\n  }\n]\n```","height":448,"width":576},"type":"n8n-nodes-base.stickyNote","position":[432,1664],"typeVersion":1,"id":"4165e1a9-9748-4d45-8bac-cc5b11fe7109","name":"Sticky Note17"},{"parameters":{"content":"### Alec message \n\n```\n[\n  {\n    \"headers\": {\n      \"host\": \"n8n-relayer-1.app.n8n.cloud\",\n      \"user-agent\": \"Zapier\",\n      \"content-length\": \"631\",\n      \"accept\": \"*/*\",\n      \"accept-encoding\": \"gzip, br\",\n      \"authorization\": \"Basic emFwaWVyOldNRXY4NDlmcGZGVlpYNkdoQjM2MGFmT3JmMWtfRFF2TlhfOFRSSjEzS1U=\",\n      \"cdn-loop\": \"cloudflare; loops=1; subreqs=1\",\n      \"cf-connecting-ip\": \"44.220.253.91\",\n      \"cf-ew-via\": \"15\",\n      \"cf-ipcountry\": \"US\",\n      \"cf-ray\": \"986f820887040616-IAD\",\n      \"cf-visitor\": \"{\\\"scheme\\\":\\\"https\\\"}\",\n      \"cf-worker\": \"n8n.cloud\",\n      \"content-type\": \"application/json; charset=utf-8\",\n      \"x-forwarded-for\": \"44.220.253.91, 172.70.42.195\",\n      \"x-forwarded-host\": \"n8n-relayer-1.app.n8n.cloud\",\n      \"x-forwarded-port\": \"443\",\n      \"x-forwarded-proto\": \"https\",\n      \"x-forwarded-server\": \"traefik-prod-users-gwc-72-585f59b6c7-ndz7z\",\n      \"x-is-trusted\": \"yes\",\n      \"x-real-ip\": \"44.220.253.91\"\n    },\n    \"params\": {},\n    \"query\": {},\n    \"body\": {\n      \"channel_id\": \"C08AVACNUER\",\n      \"channel_name\": \"data-eng-test-channel\",\n      \"conversation_id\": \"C08AVACNUER\",\n      \"event_id\": \"1758674436.000760\",\n      \"event_timestamp\": \"2025-09-24T00:40:36.000Z\",\n      \"is_message_user_bot\": \"False\",\n      \"message_text\": \"customer breakdown\",\n      \"message_timestamp\": \"2025-09-24T00:39:00.400Z\",\n      \"message_ts\": \"1758674340.400329\",\n      \"message_user_email\": \"ataggart@cribl.io\",\n      \"message_user_first_name\": \"Alec\",\n      \"message_user_id\": \"U050E77CEQP\",\n      \"message_user_last_name\": \"Taggart\",\n      \"message_user_name\": \"alec_taggart\",\n      \"reaction\": \"eyes\",\n      \"reaction_user_email\": \"nkwok@cribl.io\",\n      \"reaction_user_id\": \"U06PVBEK9T6\",\n      \"team_domain\": \"cribl\",\n      \"team_id\": \"T3XQYAF26\"\n    },\n    \"webhookUrl\": \"https://n8n-relayer-1.app.n8n.cloud/webhook-test/8394a134-6af3-4ec0-b605-3270129037cc\",\n    \"executionMode\": \"test\"\n  }\n]\n```","height":752,"width":576},"type":"n8n-nodes-base.stickyNote","position":[-768,2400],"typeVersion":1,"id":"15a790f3-8eb0-480a-b0bc-192d86aa230b","name":"Sticky Note19"},{"parameters":{"operation":"executeQuery","query":"SELECT count(*) as \"count\" FROM \"{{ $('Global Vars').first().json.snowflake_tables.dashboard_recommendations.snowflake_database }}\".\"{{ $('Global Vars').first().json.snowflake_tables.dashboard_recommendations.snowflake_schema }}\".\"{{ $('Global Vars').first().json.snowflake_tables.dashboard_recommendations.table_name }}\" WHERE event_id = '{{ $json.event_id }}'"},"type":"n8n-nodes-base.snowflake","typeVersion":1,"position":[10736,2784],"id":"6f43370b-f6ef-4895-bbcc-42b430d2148a","name":"Find Count for Event ID","credentials":{"snowflake":{"id":"G9CKV4DYGKPmDc2f","name":"Snowflake LOADER"}},"disabled":true},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict","version":2},"conditions":[{"id":"c806ba43-d60d-4a2e-8d62-281726ec7bf6","leftValue":"={{ $json.count }}","rightValue":0,"operator":{"type":"number","operation":"equals"}}],"combinator":"and"},"options":{}},"type":"n8n-nodes-base.if","typeVersion":2.2,"position":[10976,2784],"id":"6c012c01-08a9-4e23-be8c-c5d3593a0fac","name":"If","disabled":true,"onError":"continueRegularOutput"},{"parameters":{"mode":"raw","jsonOutput":"={{ $('Map Feedback to Snowflake Schema').item.json }}\n","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[11264,2768],"id":"9bedec3b-19e6-4fee-b111-1fe9b293c11b","name":"Retrieve Mapped Object","disabled":true,"onError":"continueRegularOutput"},{"parameters":{"jsCode":"const input = $input.first().json;\n\nconst mapping = input.table_schema_mapping;\nconst body = input.body;\n\nconst result = {};\n\n// 1) Map fields from body per table_schema_mapping\nfor (const [outKey, bodyKey] of Object.entries(mapping)) {\n  result[outKey] = body?.[bodyKey];\n}\n\n// 2) Copy every other top-level key except \"body\" and \"table_schema_mapping\"\n//    Don't overwrite keys already set from the mapping.\nfor (const [key, value] of Object.entries(input)) {\n  if (key === 'body' || key === 'table_schema_mapping') continue;\n  if (key in mapping) continue; // avoid clobbering mapped fields\n  result[key] = value.trim();\n}\n\nreturn result;\n"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[10400,2544],"id":"c8665971-b383-41e8-af36-b48b52b1e76f","name":"Map Feedback to Snowflake Schema"},{"parameters":{"mode":"raw","jsonOutput":"={\n  \"body\": {{ $('Global Vars').first().json.body.toJsonString() }},\n  \"table_schema_mapping\": {\n    \"event_id\": \"event_id\",\n    \"event_timestamp\": \"event_timestamp\",\n    \"message_ts\": \"message_ts\",\n    \"message_timestamp\": \"message_timestamp\",\n    \"message_text\": \"message_text\",\n    \"message_user_name\": \"message_user_name\",\n    \"message_user_email\": \"message_user_email\",\n    \"message_user_id\": \"message_user_id\",\n    \"reaction\": \"reaction\",\n    \"reaction_user_id\": \"reaction_user_id\",\n    \"reaction_user_email\": \"reaction_user_email\",\n    \"channel_id\": \"channel_id\",\n    \"channel_name\": \"channel_name\",\n    \"conversation_id\": \"conversation_id\",\n    \"team_id\": \"team_id\",\n    \"team_domain\": \"team_domain\"\n  },\n  \"retrieved_document_ids\": {{ JSON.stringify($('Aggregate Document Ids').first().json.document_ids.toJsonString())\n  }},\n\n  \"retrieved_document_id_counts\": {{ \n    JSON.stringify(\n      Object.fromEntries($('Map Reduce Document Counts').first().json.output.map(\n            item => [item.document_id, item.count]\n          )).toJsonString()\n    )\n  }},\n\n  {{ $json.toJsonString().slice(1, -1) }}\n  \n  \n}","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[10160,2544],"id":"82b28d3e-e479-4a61-bdd3-85103d714eda","name":"Insert Table Schema Mapping","alwaysOutputData":true,"onError":"continueRegularOutput"},{"parameters":{"content":"## Save recommendation to Snowflake `dashboard_recommendations`","height":656,"width":1120,"color":6},"type":"n8n-nodes-base.stickyNote","position":[10608,2336],"typeVersion":1,"id":"a3a69cbe-51a0-4289-bb5e-3d944834c743","name":"Sticky Note20"},{"parameters":{"content":"## Map-Reduce to rank suggested docs\n1. Aggregate all document ids (has duplicates)\n2. Get document id with count\n3. Rank by count desc","height":656,"width":976,"color":3},"type":"n8n-nodes-base.stickyNote","position":[7504,2336],"typeVersion":1,"id":"83350bc9-5e7f-4491-bf68-0f725a9c36a3","name":"Sticky Note21"},{"parameters":{"content":"filter for if has error? \nrest of output might still be good? \nerror message send to slack at all? \n"},"type":"n8n-nodes-base.stickyNote","position":[7520,2144],"typeVersion":1,"id":"6c08664d-7f69-47ee-8ab9-2a0f20fff00b","name":"Sticky Note22"},{"parameters":{"content":"```\nCREATE TABLE IF NOT EXISTS dashboard_recommendations (\n    -- Event identifiers\n    event_id VARCHAR(17) PRIMARY KEY,                    -- \"1758674436.000760\"\n    event_timestamp TIMESTAMP_TZ NOT NULL,               -- \"2025-09-24T00:40:36.000Z\"\n\n    -- Message information\n    message_ts VARCHAR(17) NOT NULL,                     -- \"1758674340.400329\"\n    message_timestamp TIMESTAMP_TZ NOT NULL,             -- \"2025-09-24T00:39:00.400Z\"\n    message_text TEXT NOT NULL,                                   -- \"customer breakdown\"\n\n    -- Message user information\n    message_user_name VARCHAR(100),                      -- \"alec_taggart\"\n    message_user_email VARCHAR(75) NOT NULL,                     -- \"ataggart@cribl.io\"\n    message_user_id VARCHAR(11) NOT NULL,               -- \"U050E77CEQP\"\n\n    -- Reaction information\n    reaction VARCHAR(50) NOT NULL,                       -- \"eyes\"\n    reaction_user_id VARCHAR(11) NOT NULL,               -- \"U06PVBEK9T6\"\n    reaction_user_email VARCHAR(75) NOT NULL,                    -- \"nkwok@cribl.io\"\n\n    -- Channel and conversation context\n    channel_id VARCHAR(11) NOT NULL,                     -- \"C08AVACNUER\"\n    channel_name VARCHAR(255),                           -- \"data-eng-test-channel\"\n    conversation_id VARCHAR(11),                         -- \"C08AVACNUER\"\n\n    -- Team/workspace information\n    team_id VARCHAR(9) NOT NULL,                        -- \"T3XQYAF26\"\n    team_domain VARCHAR(100),                            -- \"cribl\"\n\n    -- Metadata timestamps\n    created_at TIMESTAMP_TZ DEFAULT CURRENT_TIMESTAMP(),\n    updated_at TIMESTAMP_TZ DEFAULT CURRENT_TIMESTAMP()\n);\n```","height":144,"width":640},"type":"n8n-nodes-base.stickyNote","position":[10064,2080],"typeVersion":1,"id":"b29ad6aa-e2ca-4db0-83b3-cca60ea14e31","name":"Sticky Note23"},{"parameters":{"content":"```\n[\n  {\n    \"headers\": {\n      \"host\": \"n8n-relayer-1.app.n8n.cloud\",\n      \"user-agent\": \"PostmanRuntime/7.47.1\",\n      \"content-length\": \"948\",\n      \"accept\": \"*/*\",\n      \"accept-encoding\": \"gzip, br\",\n      \"authorization\": \"Basic emFwaWVyOldNRXY4NDlmcGZGVlpYNkdoQjM2MGFmT3JmMWtfRFF2TlhfOFRSSjEzS1U=\",\n      \"cdn-loop\": \"cloudflare; loops=1; subreqs=1\",\n      \"cf-connecting-ip\": \"172.56.42.92\",\n      \"cf-ew-via\": \"15\",\n      \"cf-ipcountry\": \"US\",\n      \"cf-ray\": \"986fe3e933d24b1f-LAX\",\n      \"cf-visitor\": \"{\\\"scheme\\\":\\\"https\\\"}\",\n      \"cf-worker\": \"n8n.cloud\",\n      \"content-type\": \"application/json\",\n      \"x-forwarded-for\": \"172.56.42.92, 104.23.251.97\",\n      \"x-forwarded-host\": \"n8n-relayer-1.app.n8n.cloud\",\n      \"x-forwarded-port\": \"443\",\n      \"x-forwarded-proto\": \"https\",\n      \"x-forwarded-server\": \"traefik-prod-users-gwc-72-585f59b6c7-ndz7z\",\n      \"x-is-trusted\": \"yes\",\n      \"x-real-ip\": \"172.56.42.92\"\n    },\n    \"params\": {},\n    \"query\": {},\n    \"body\": {\n      \"channel_id\": \"C0912AANW1L\",\n      \"channel_name\": \"data-eng-test-ai-channel\",\n      \"conversation_id\": \"C0912AANW1L\",\n      \"event_id\": \"1759194864.008200\",\n      \"event_timestamp\": \"2025-09-30T01:14:24.008Z\",\n      \"is_message_user_bot\": \"False\",\n      \"message_text\": \"Hi team - Is there a dashboard in Omni to see free cribl cloud users, and associated email addresses within accounts I own similar to https://cribl.cloud.looker.com/explore/Product/cloud_orgs?qid=6AczKnvfgAdLscURN8AKDq&amp;toggle=filthis one> I used in looker?\",\n      \"message_timestamp\": \"2025-09-30T01:14:21.395Z\",\n      \"message_ts\": \"1759194861.395459\",\n      \"message_user_email\": \"nkwok@cribl.io\",\n      \"message_user_first_name\": \"Nathan\",\n      \"message_user_id\": \"U06PVBEK9T6\",\n      \"message_user_last_name\": \"Kwok\",\n      \"message_user_name\": \"nathan_kwok\",\n      \"reaction\": \"omni\",\n      \"reaction_user_email\": \"nkwok@cribl.io\",\n      \"reaction_user_id\": \"U06PVBEK9T6\",\n      \"team_domain\": \"cribl\",\n      \"team_id\": \"T3XQYAF26\"\n    },\n    \"webhookUrl\": \"https://n8n-relayer-1.app.n8n.cloud/webhook-test/8394a134-6af3-4ec0-b605-3270129037cc\",\n    \"executionMode\": \"test\"\n  }\n]\n```","height":640,"width":704},"type":"n8n-nodes-base.stickyNote","position":[-864,3312],"typeVersion":1,"id":"ef4a4f6c-8ec9-41e9-852c-32be09cccc47","name":"Sticky Note1"},{"parameters":{"workflowId":{"__rl":true,"value":"OFpD7aepKHcHCvqz","mode":"list","cachedResultUrl":"/workflow/OFpD7aepKHcHCvqz","cachedResultName":"Global Vars"},"workflowInputs":{"mappingMode":"defineBelow","value":{}},"options":{}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[704,1488],"id":"91c9d361-6758-4c06-b64f-2e5b149760cc","name":"Global Vars"},{"parameters":{"url":"={{ $('Global Vars').first().json.omni_api.omni_base_url }}/api/v1/documents/{{ $json.document_ids }}/permissions?userId={{ $('Global Vars').first().json.omni_api.omni_user_id }}","authentication":"genericCredentialType","genericAuthType":"httpBearerAuth","options":{"response":{"response":{"fullResponse":true,"neverError":true,"responseFormat":"json"}}}},"type":"n8n-nodes-base.httpRequest","typeVersion":4.2,"position":[6432,2544],"id":"da05c8c8-c9fe-4840-89e3-c7efe94df562","name":"Get Document Permissions for User Id","alwaysOutputData":false,"credentials":{"httpBearerAuth":{"id":"5VdIyCQ3QBhEpyIx","name":"Omni API"}},"onError":"continueRegularOutput"},{"parameters":{"assignments":{"assignments":[{"id":"baa27ca0-bd33-4e8c-86ed-b03bbff2d2c5","name":"permits","value":"={{ $json.body.permits }}","type":"array"},{"id":"6cae7aae-fc2e-422a-b27b-5fe3bdd0608e","name":"document_id","value":"={{ $('For each unique document id').item.json.document_ids }}","type":"string"},{"id":"00e5f5fc-236c-4f14-ad14-3ec592aa149a","name":"status_code","value":"={{ $json.statusCode }}","type":"number"}]},"options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[6640,2544],"id":"ce4eb44b-428b-4fb2-9933-0486abcc5a98","name":"Merge Permits and Document Ids","onError":"continueRegularOutput"},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict","version":2},"conditions":[{"id":"497bc14a-115b-428f-99f6-1c32b5489e04","leftValue":"={{ $json.status_code }}","rightValue":200,"operator":{"type":"number","operation":"equals"}},{"id":"e71ab3c2-013c-47e4-8088-5dfab923abc4","leftValue":"={{ $json.permits }}","rightValue":0,"operator":{"type":"array","operation":"lengthGt","rightType":"number"}}],"combinator":"and"},"options":{}},"type":"n8n-nodes-base.filter","typeVersion":2.2,"position":[6864,2544],"id":"677944aa-587f-42a2-b1b0-d41a2b347428","name":"Filter out no permissions documents","onError":"continueRegularOutput"},{"parameters":{"fieldsToAggregate":{"fieldToAggregate":[{"fieldToAggregate":"document_ids","renameField":true,"outputFieldName":"document_ids"}]},"options":{}},"type":"n8n-nodes-base.aggregate","typeVersion":1,"position":[5680,2544],"id":"0d11a99b-a8e3-4022-9a8f-fca9f30c6a90","name":"Aggregate Document Ids","onError":"continueRegularOutput"},{"parameters":{"content":"## Filter out documents that user doesn't have permissions to\n- for each document, check the document permissions object for that user","height":464,"width":1152,"color":7},"type":"n8n-nodes-base.stickyNote","position":[6128,2368],"typeVersion":1,"id":"39c35616-2ed9-495a-91c7-3c5e5aa2ec47","name":"Sticky Note25"},{"parameters":{"mode":"raw","jsonOutput":"={\n  \"output\": {\n    \"process_name\": \"keyword_document_name_search_results\",\n    \"document_ids\": {{ $json.document_ids }}\n  }\n}\n","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[5264,2896],"id":"c468c28d-00aa-4a55-a6fb-a4ded16262e4","name":"Keyword Document Name Search Results JSON"},{"parameters":{"mode":"raw","jsonOutput":"={\n  \"output\": {\n    \"process_name\": \"keyword_document_query_name_search_results\",\n    \"document_ids\": {{ $json.document_ids }}\n  }\n}\n","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[5264,3136],"id":"ddd1c7de-e62e-4d8c-81cf-5b14868db87f","name":"Keyword Document Query Name Search Results JSON"},{"parameters":{"mode":"raw","jsonOutput":"={\n  \"output\": {\n    \"process_name\": \"keyword_document_query_table_search_results\",\n    \"document_ids\": {{ $json.document_ids }}\n  }\n}\n","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[5264,3360],"id":"00d5d78c-6e08-4970-92f1-7bcab72630ab","name":"Keyword Document Query Table Search Results JSON"},{"parameters":{"mode":"raw","jsonOutput":"={\n  \"output\": {\n    \"process_name\": \"topic_document_search_results\",\n    \"document_ids\": {{ $json.document_ids }}\n  }\n}","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[5264,3600],"id":"fc4a99b3-e227-4c86-927a-19dfa4b1c820","name":"Topic Document Search Results JSON"},{"parameters":{"numberInputs":6},"type":"n8n-nodes-base.merge","typeVersion":3.2,"position":[5776,3184],"id":"c28dc938-dfa0-4fcd-8d6d-35f19b4489b2","name":"Merge"},{"parameters":{"fieldsToAggregate":{"fieldToAggregate":[{"fieldToAggregate":"output"}]},"options":{}},"type":"n8n-nodes-base.aggregate","typeVersion":1,"position":[6016,3248],"id":"8c9a95ab-ab1c-41b2-9d5d-889848d36bee","name":"Aggregate"},{"parameters":{"mode":"raw","jsonOutput":"={\n  \"output\": {\n    \"extracted_keywords\": {{ $json.extracted_keywords }},\n    \"omni_picked_topics\": {{ $json.omni_picked_topics }},\n\n    \"retrieved_document_ids_by_process\": {{ $('Aggregate').item.json.output.reduce((a,{process_name,document_ids}) => (a[process_name]=document_ids, a), {}).toJsonString()\n       }},\n\n    {{ Object.fromEntries(\n        $('Aggregate').item.json.output.map(\n          ({ process_name, document_ids }) => [process_name, document_ids]\n        )\n      ).toJsonString().slice(1, -1)\n    }}\n  }\n}","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[8784,3248],"id":"1ff1fcf8-341e-470d-8efc-e9af880e751f","name":"Process Metadata","alwaysOutputData":true},{"parameters":{"content":"## Data Transformation for Insertion\n- store list of document ids that were rec'ed\n- store list of keywords\n- store list of topics","height":656,"width":1200,"color":4},"type":"n8n-nodes-base.stickyNote","position":[9360,2336],"typeVersion":1,"id":"5e988258-5e1e-4cac-8b46-77d04b9e27d1","name":"Sticky Note26"},{"parameters":{"jsCode":"const input = $input.first().json;\n\nconst stringifiedSecond = Object.fromEntries(\n  Object.entries(input.output[1] ?? {}).map(([k, v]) => [k, JSON.stringify(v)])\n);\n\n\nconst mergedSecond = {\n  ...stringifiedSecond,\n  recommended_document_ids: JSON.stringify([...($input.first().json.output[0]?.document_ids ?? [])]),\n  recommendation_text: $input.first().json.output[0]?.message ?? \"\"\n};\n\nreturn mergedSecond;\n\n\n"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[9904,2544],"id":"c48ba9ee-84c3-44d8-a184-9c77066888f1","name":"Insert recommended_document_ids with Process Results","onError":"continueRegularOutput"},{"parameters":{},"type":"n8n-nodes-base.merge","typeVersion":3.2,"position":[9440,2544],"id":"db326fc5-48c7-4b1a-9cf6-8d60fb2c71ac","name":"Merge Recommendation Agent with Process Results","onError":"continueRegularOutput"},{"parameters":{"fieldsToAggregate":{"fieldToAggregate":[{"fieldToAggregate":"output"}]},"options":{}},"type":"n8n-nodes-base.aggregate","typeVersion":1,"position":[9664,2544],"id":"5a391ae5-2640-45d1-bd39-56ea59225f03","name":"Aggregate to Single Object","onError":"continueRegularOutput"},{"parameters":{"content":"```\n{\n  \"body\": {{ $('Global Vars').first().json.body.toJsonString() }},\n  \"table_schema_mapping\": {\n    \"event_id\": \"event_id\",\n    \"event_timestamp\": \"event_timestamp\",\n    \"message_ts\": \"message_ts\",\n    \"message_timestamp\": \"message_timestamp\",\n    \"message_text\": \"message_text\",\n    \"message_user_name\": \"message_user_name\",\n    \"message_user_email\": \"message_user_email\",\n    \"message_user_id\": \"message_user_id\",\n    \"reaction\": \"reaction\",\n    \"reaction_user_id\": \"reaction_user_id\",\n    \"reaction_user_email\": \"reaction_user_email\",\n    \"channel_id\": \"channel_id\",\n    \"channel_name\": \"channel_name\",\n    \"conversation_id\": \"conversation_id\",\n    \"team_id\": \"team_id\",\n    \"team_domain\": \"team_domain\"\n  },\n  \"retrieved_document_ids\": {{ JSON.stringify($('Aggregate Document Ids').first().json.document_ids.toJsonString())\n  }},\n\n  \"retrieved_document_id_counts\": {{ \n    JSON.stringify(\n      Object.fromEntries($('Map Reduce Document Count').first().json.output.map(\n            item => [item.document_id, item.count]\n          )).toJsonString()\n    )\n  }},\n\n  {{ $json.toJsonString().slice(1, -1) }}\n  \n  \n}\n```","height":416,"width":528},"type":"n8n-nodes-base.stickyNote","position":[10080,2768],"typeVersion":1,"id":"58c7671a-be48-461f-9f3c-a7cfaf09563c","name":"Sticky Note27"},{"parameters":{"content":"## Slack Message on Error\n- include input body\n- include workflow execution link","height":272,"width":416,"color":3},"type":"n8n-nodes-base.stickyNote","position":[9360,2000],"typeVersion":1,"id":"f65c9627-54c8-41bc-b539-4e38d37abd00","name":"Sticky Note24"},{"parameters":{"workflowId":{"__rl":true,"value":"1pR9HTgBxYcoiL27","mode":"list","cachedResultUrl":"/workflow/1pR9HTgBxYcoiL27","cachedResultName":"Cortex Search"},"workflowInputs":{"mappingMode":"defineBelow","value":{"query_string":"={{ $json.output.toJsonString() }}","service_name":"omni_documents_search_service","limit":1},"matchingColumns":[],"schema":[{"id":"query_string","displayName":"query_string","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"service_name","displayName":"service_name","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"limit","displayName":"limit","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"number","removed":false}],"attemptToConvertTypes":true,"convertFieldsToString":true},"mode":"each","options":{"waitForSubWorkflow":true}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[3792,1488],"id":"043ca1b6-2e0e-4530-bd90-d507ae71b9fc","name":"Cortex Document Name Search"},{"parameters":{"workflowId":{"__rl":true,"value":"1pR9HTgBxYcoiL27","mode":"list","cachedResultUrl":"/workflow/1pR9HTgBxYcoiL27","cachedResultName":"Cortex Search"},"workflowInputs":{"mappingMode":"defineBelow","value":{"query_string":"={{ $json.output.toJsonString() }}","service_name":"omni_document_queries_query_name_search_service","limit":3},"matchingColumns":[],"schema":[{"id":"query_string","displayName":"query_string","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"service_name","displayName":"service_name","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"limit","displayName":"limit","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"number","removed":false}],"attemptToConvertTypes":true,"convertFieldsToString":true},"mode":"each","options":{"waitForSubWorkflow":true}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[3792,1712],"id":"c3d38230-e724-46f9-a62d-b2382cf78283","name":"Cortex Document Query Name Search"},{"parameters":{"workflowId":{"__rl":true,"value":"1pR9HTgBxYcoiL27","mode":"list","cachedResultUrl":"/workflow/1pR9HTgBxYcoiL27","cachedResultName":"Cortex Search"},"workflowInputs":{"mappingMode":"defineBelow","value":{"query_string":"={{ $json.output.toJsonString() }}","service_name":"omni_document_queries_query_table_search_service","limit":6},"matchingColumns":[],"schema":[{"id":"query_string","displayName":"query_string","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"service_name","displayName":"service_name","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"limit","displayName":"limit","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"number","removed":false}],"attemptToConvertTypes":true,"convertFieldsToString":true},"mode":"each","options":{"waitForSubWorkflow":true}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[3792,1936],"id":"8b59d534-b8c5-4350-b8ab-05709d91a349","name":"Cortex Document Query Table Search"},{"parameters":{"workflowId":{"__rl":true,"value":"1pR9HTgBxYcoiL27","mode":"list","cachedResultUrl":"/workflow/1pR9HTgBxYcoiL27","cachedResultName":"Cortex Search"},"workflowInputs":{"mappingMode":"defineBelow","value":{"query_string":"={{ $json.output.toJsonString() }}","service_name":"omni_documents_search_service","limit":1},"matchingColumns":[],"schema":[{"id":"query_string","displayName":"query_string","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"service_name","displayName":"service_name","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"limit","displayName":"limit","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"number","removed":false}],"attemptToConvertTypes":true,"convertFieldsToString":true},"mode":"each","options":{"waitForSubWorkflow":true}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[3712,2560],"id":"7fa2f1d9-c4b5-4bb8-88ee-9af91ffece15","name":"Cortex Document Name Search1","onError":"continueRegularOutput"},{"parameters":{"workflowId":{"__rl":true,"value":"1pR9HTgBxYcoiL27","mode":"list","cachedResultUrl":"/workflow/1pR9HTgBxYcoiL27","cachedResultName":"Cortex Search"},"workflowInputs":{"mappingMode":"defineBelow","value":{"query_string":"={{ $json.output.toJsonString() }}","service_name":"omni_document_queries_query_name_search_service","limit":4},"matchingColumns":[],"schema":[{"id":"query_string","displayName":"query_string","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"service_name","displayName":"service_name","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"limit","displayName":"limit","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"number","removed":false}],"attemptToConvertTypes":true,"convertFieldsToString":true},"mode":"each","options":{"waitForSubWorkflow":true}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[3712,2816],"id":"53eb764b-de8f-48a4-bf2a-9b00087244c6","name":"Cortex Document Query Name Search1","onError":"continueRegularOutput"},{"parameters":{"workflowId":{"__rl":true,"value":"1pR9HTgBxYcoiL27","mode":"list","cachedResultUrl":"/workflow/1pR9HTgBxYcoiL27","cachedResultName":"Cortex Search"},"workflowInputs":{"mappingMode":"defineBelow","value":{"query_string":"={{ $json.output.toJsonString() }}","service_name":"omni_document_queries_query_table_search_service","limit":6},"matchingColumns":[],"schema":[{"id":"query_string","displayName":"query_string","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"service_name","displayName":"service_name","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"limit","displayName":"limit","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"number","removed":false}],"attemptToConvertTypes":true,"convertFieldsToString":true},"mode":"each","options":{"waitForSubWorkflow":true}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[3712,3040],"id":"5fb4b076-ee6c-43ca-908b-164141f7149a","name":"Cortex Document Query Table Search1","onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nconsole.log($input.all())\n\nconst document_ids = []\n\nfor (const item of $input.all()) {\n  document_ids.push(...item.json.document_ids);\n}\n\n// return $input.all();\n\nreturn [\n  {\n    \"document_ids\": document_ids\n  }\n];"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[4000,2816],"id":"3d40c4af-1ba1-417d-b95c-c68a7d3090b9","name":"Gather Document Ids","onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nconsole.log($input.all())\n\nconst document_ids = []\n\nfor (const item of $input.all()) {\n  document_ids.push(...item.json.document_ids);\n}\n\n// return $input.all();\n\nreturn [\n  {\n    \"document_ids\": document_ids\n  }\n];"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[4000,2560],"id":"5ba1eca1-d046-42b5-8541-4f2cd1cf3a1c","name":"Gather Document Ids1","onError":"continueRegularOutput"},{"parameters":{"workflowId":{"__rl":true,"value":"RMfcJExZ0DdXdMnJ","mode":"list","cachedResultUrl":"/workflow/RMfcJExZ0DdXdMnJ","cachedResultName":"Slack Error"},"workflowInputs":{"mappingMode":"defineBelow","value":{"headers_host":"={{ $('Webhook').first().json.headers.host }}","body":"={{ $('Webhook').first().json.body }}","workflow":"={{ $workflow }}","execution":"={{ $execution }}"},"matchingColumns":["zapier_slack_response_webhook_webhook_url","body_toJsonString","headers_host","body"],"schema":[{"id":"body","displayName":"body","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"object","removed":false},{"id":"headers_host","displayName":"headers_host","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"string","removed":false},{"id":"workflow","displayName":"workflow","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"object","removed":false},{"id":"execution","displayName":"execution","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"object","removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":true},"options":{}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.2,"position":[9520,2112],"name":"Call Slack Error","id":"fd8bb69d-d218-4266-8b62-978fa31abb70"},{"parameters":{"content":"### Thread Conversation Text\n```\n[\n  {\n    \"headers\": {\n      \"host\": \"n8n-relayer-1.app.n8n.cloud\",\n      \"user-agent\": \"Zapier\",\n      \"content-length\": \"3179\",\n      \"accept\": \"*/*\",\n      \"accept-encoding\": \"gzip, br\",\n      \"authorization\": \"Basic emFwaWVyOldNRXY4NDlmcGZGVlpYNkdoQjM2MGFmT3JmMWtfRFF2TlhfOFRSSjEzS1U=\",\n      \"cdn-loop\": \"cloudflare; loops=1; subreqs=1\",\n      \"cf-connecting-ip\": \"3.238.152.42\",\n      \"cf-ew-via\": \"15\",\n      \"cf-ipcountry\": \"US\",\n      \"cf-ray\": \"98886a9940a6c655-IAD\",\n      \"cf-visitor\": \"{\\\"scheme\\\":\\\"https\\\"}\",\n      \"cf-worker\": \"n8n.cloud\",\n      \"content-type\": \"application/json; charset=utf-8\",\n      \"x-forwarded-for\": \"3.238.152.42, 104.23.211.189\",\n      \"x-forwarded-host\": \"n8n-relayer-1.app.n8n.cloud\",\n      \"x-forwarded-port\": \"443\",\n      \"x-forwarded-proto\": \"https\",\n      \"x-forwarded-server\": \"traefik-prod-users-gwc-72-585f59b6c7-kn8mt\",\n      \"x-is-trusted\": \"yes\",\n      \"x-real-ip\": \"3.238.152.42\"\n    },\n    \"params\": {},\n    \"query\": {},\n    \"body\": {\n      \"channel_id\": \"C0912AANW1L\",\n      \"channel_name\": \"data-eng-test-ai-channel\",\n      \"conversation_id\": \"C0912AANW1L\",\n      \"event_id\": \"1759452311.006000\",\n      \"event_timestamp\": \"2025-10-03T00:45:11.006Z\",\n      \"is_message_user_bot\": \"False\",\n      \"message_text\": \"We're being asked to present a discounting analysis at the next Pricing Committee meeting. We used to have a dashboard with discounting by band in Looker but having trouble finding it in Omni. Do we have that dash in Omni?\",\n      \"message_thread_ts\": \"1759451703.287339\",\n      \"message_thread_ts_time\": \"2025-10-03T00:35:03.000Z\",\n      \"message_timestamp\": \"2025-10-03T00:35:03.287Z\",\n      \"message_ts\": \"1759451703.287339\",\n      \"message_user_email\": \"nkwok@cribl.io\",\n      \"message_user_first_name\": \"Nathan\",\n      \"message_user_id\": \"U06PVBEK9T6\",\n      \"message_user_last_name\": \"Kwok\",\n      \"message_user_name\": \"nathan_kwok\",\n      \"reaction\": \"omni\",\n      \"reaction_user_email\": \"nkwok@cribl.io\",\n      \"reaction_user_id\": \"U06PVBEK9T6\",\n      \"team_domain\": \"cribl\",\n      \"team_id\": \"T3XQYAF26\",\n      \"thread_conversation_text\": \"We're being asked to present a discounting analysis at the next Pricing Committee meeting. We used to have a dashboard with discounting by band in Looker but having trouble finding it in Omni. Do we have that dash in Omni? \\\\n#__--__#\\\\n<@U06PVBEK9T6> It looks like youre looking for an Omni dashboard with pricing and discount analysis similar to your previous Looker report. These dashboards might contain what you need:\\n <https://cribl.omniapp.co/dashboards/f36024ab|Overview: Deal Pricing Summary> in <https://cribl.omniapp.co/f/gtm leads|GTM Leads>\\n <https://cribl.omniapp.co/dashboards/2829e291|Team: Digital &amp; Demand Channel Analysis> in <https://cribl.omniapp.co/f/marketing|Marketing>\\n <https://cribl.omniapp.co/dashboards/45d06a29|Overview: Azure Cost Metrics> in <https://cribl.omniapp.co/f/engineering|Engineering> \\\\n#__--__#\\\\nthis is good, deal pricing summary in gtm leads is good \\\\n#__--__#\\\\n<@U06PVBEK9T6>\\n\\nIt looks like youre searching for discounting and deal pricing insights for the upcoming Pricing Committee meeting. These dashboards might contain the analysis you need:\\n <https://cribl.omniapp.co/dashboards/f36024ab|Overview: Deal Pricing Summary> exists in <https://cribl.omniapp.co/f/gtm leads|GTM Leads>\\n <https://cribl.omniapp.co/dashboards/2829e291|Team: Digital &amp; Demand Channel Analysis> exists in <https://cribl.omniapp.co/f/marketing|Marketing>\\n <https://cribl.omniapp.co/dashboards/6fd01f76|Team: Lead Creation &amp; Conversion> exists in <https://cribl.omniapp.co/f/marketing|Marketing> \\\\n#__--__#\\\\nthis should be the 3rd message \\\\n#__--__#\\\\n<@U06PVBEK9T6> Regarding your discounting analysis for the Pricing Committee, here are some dashboards that might contain what you need:\\n- <https://cribl.omniapp.co/dashboards/f36024ab|Overview: Deal Pricing Summary> in <https://cribl.omniapp.co/f/gtm leads|GTM Leads>\\n- <https://cribl.omniapp.co/dashboards/2829e291|Team: Digital &amp; Demand Channel Analysis> in <https://cribl.omniapp.co/f/marketing|Marketing>\\n- <https://cribl.omniapp.co/dashboards/c1d2a194|Team: Marketing Qualified Opps Insights> in <https://cribl.omniapp.co/f/marketing|Marketing> \\\\n#__--__#\\\\nthis should the 4th message\"\n    },\n    \"webhookUrl\": \"https://n8n-relayer-1.app.n8n.cloud/webhook/8394a134-6af3-4ec0-b605-3270129037cc\",\n    \"executionMode\": \"production\"\n  }\n]\n```","height":784,"width":720},"type":"n8n-nodes-base.stickyNote","position":[-800,1568],"typeVersion":1,"id":"c913842e-f95c-4fc8-b90b-599d610fd768","name":"Sticky Note29"},{"parameters":{"jsCode":"// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nconsole.log($input.all())\n\nconst document_ids = []\n\nfor (const item of $input.all()) {\n  document_ids.push(...item.json.document_ids);\n}\n\n// return $input.all();\n\nreturn [\n  {\n    \"document_ids\": document_ids\n  }\n];"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[4112,1488],"id":"06f996a9-dbe9-4983-a811-d63073ef6a6b","name":"Gather Document Ids2"},{"parameters":{"jsCode":"// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nconsole.log($input.all())\n\nconst document_ids = []\n\nfor (const item of $input.all()) {\n  document_ids.push(...item.json.document_ids);\n}\n\n// return $input.all();\n\nreturn [\n  {\n    \"document_ids\": document_ids\n  }\n];"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[4112,1712],"id":"353cfed2-f942-4934-aa88-1ddab5b3e8c6","name":"Gather Document Ids3"},{"parameters":{"jsCode":"// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nconsole.log($input.all())\n\nconst document_ids = []\n\nfor (const item of $input.all()) {\n  document_ids.push(...item.json.document_ids);\n}\n\n// return $input.all();\n\nreturn [\n  {\n    \"document_ids\": document_ids\n  }\n];"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[4112,1936],"id":"2c99f5db-4c22-41b7-af2d-8a14b674194b","name":"Gather Document Ids4"},{"parameters":{"table":"={{ $('Global Vars').first().json.snowflake_tables.dashboard_recommendations.table_name }}","columns":"={{ $('Retrieve Mapped Object').item.json.keys().join(\",\") }}"},"type":"n8n-nodes-base.snowflake","typeVersion":1,"position":[11504,2768],"id":"c6f0a58f-c2c0-45c0-81b6-a1d08e6e6b54","name":"Insert Recommendation into Snowflake","credentials":{"snowflake":{"id":"G9CKV4DYGKPmDc2f","name":"Snowflake LOADER"}},"disabled":true},{"parameters":{"toolDescription":"Make a request to Omni API to pick a topic relevant to the query","method":"POST","url":"={{ $('Global Vars').item.json.omni_api.omni_base_url }}/api/v1/ai/pick-topic","authentication":"genericCredentialType","genericAuthType":"httpBearerAuth","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={\n  \"modelId\": {{ $json.omni_api.model_id.toJsonString() }},\n  \"prompt\": {{ $fromAI('sanitized_text', ``, 'string').toJsonString() }}\n}","options":{}},"type":"n8n-nodes-base.httpRequestTool","typeVersion":4.2,"position":[3136,2848],"id":"fee736ee-6a8b-4eda-82d9-9729e052bb86","name":"Omni Pick Topic Tool","credentials":{"httpBearerAuth":{"id":"5VdIyCQ3QBhEpyIx","name":"Omni API"}}},{"parameters":{"promptType":"define","text":"=<task>\n1. Sanitize the input_query so that it removes any double quotes. The result of this must be a valid JSON string that can be used as a JSON value. The sanitized input_query should be called `sanitized_text` .\n1. Make 3 API requests using the pick topic tool to get topic names that are closest to the `sanitized_text` .\n2. Each tool call will result in a topicName. The results from the pick topic tool calls needs to be aggregated into a list of strings, with the key to the list being `topic_name`.\n3. **CRITICAL**: Deduplicate the `topic_name` list so that the list contains only a unique set of topic names.\n</task>\n\n<input_query>\n{{ $json.body.thread_conversation_text.toJsonString() }}\n</input_query>\n\n<output_format>\nReturn a structured JSON **list** of unique topic names.\n</output_format>","hasOutputParser":true,"needsFallback":true,"options":{"systemMessage":"You are an expert data analyst who has built many dashboards in the Omni Analytics tool, which is a business intelligence tool, that sits on top of Snowflake data through dbt. You triage natural language queries from Stakeholders within the company in order to find the best dashboard (otherwise known as document) to answer the question. Documents, also known as dashboards, are parents of document queries, which are individual queries that run against the data within the parent document. Metadata on the documents and document queries and document query filters are stored in Snowflake and can be accessed through the Cortex Search Service and the Cortex Analyst tools."}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":2.2,"position":[2960,2560],"id":"9688d073-3add-490c-9e67-1b0c6452f634","name":"Topics Agent","retryOnFail":true,"onError":"continueRegularOutput"},{"parameters":{"modelName":"models/gemini-2.5-pro","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[2816,2752],"id":"a309b01b-24d4-4b1f-a763-c6267f9db68b","name":"Topics Agent Gemini 2.5 Pro","credentials":{"googlePalmApi":{"id":"LKQbGwmroZKBfciU","name":"Gemini - Cribl"}}},{"parameters":{"model":"gpt-4","options":{"responseFormat":"json_object"}},"type":"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi","typeVersion":1,"position":[2816,2960],"id":"a97c62f7-acb2-48c5-93d9-eb80e95ba16b","name":"Topics Agent gpt-4","credentials":{"azureOpenAiApi":{"id":"nBB3SsSM4Tq7RNAe","name":"Azure OpenAI gpt-4"}}},{"parameters":{"jsonSchemaExample":"[\n  \n    \"topic_name_1\",\n    \"topic_name_2\",\n    \"topic_name_3\"\n  \n]\n"},"type":"@n8n/n8n-nodes-langchain.outputParserStructured","typeVersion":1.3,"position":[3280,2752],"id":"92ee9d73-b659-4339-be00-5d3ea0be206b","name":"Deduplicated Topics Structured Output"},{"parameters":{"workflowId":{"__rl":true,"value":"5fLEtpYDMhJTTEzh","mode":"list","cachedResultUrl":"/workflow/5fLEtpYDMhJTTEzh","cachedResultName":"Insert into Snowflake Table"},"workflowInputs":{"mappingMode":"defineBelow","value":{"snowflake_table_obj":"={{ $('Global Vars').first().json.snowflake_tables.dashboard_recommendations }}","primary_keys":"[\"event_id\"]","save_obj":"={{ $json }}"},"matchingColumns":[],"schema":[{"id":"save_obj","displayName":"save_obj","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"object","removed":false},{"id":"primary_keys","displayName":"primary_keys","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"array","removed":false},{"id":"snowflake_table_obj","displayName":"snowflake_table_obj","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"object","removed":false}],"attemptToConvertTypes":true,"convertFieldsToString":true},"mode":"each","options":{}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[10736,2544],"id":"f0a9982e-6c63-4498-8fee-71c5f41b3ed1","name":"Call 'Insert into Snowflake Table'"},{"parameters":{"model":"o4-mini","options":{"responseFormat":"json_object"}},"type":"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi","typeVersion":1,"position":[8000,3008],"id":"1297d905-d2c3-424e-bf8f-6a7b0a59a895","name":"Map Reduce Agent o4-mini4","credentials":{"azureOpenAiApi":{"id":"N96DE6AiByL8h8kA","name":"Azure Open AI o4-mini"}},"disabled":true},{"parameters":{"content":"```\nCREATE TABLE N8N_WORKFLOW_EXECUTIONS (\n  INPUT_OBJECT TEXT /* JSON or any text payload */,\n  EXECUTION_ID INTEGER NOT NULL /* integer */,\n  WORKFLOW_ID TEXT NOT NULL /* string */,\n  WORKFLOW_NAME TEXT /* string */,\n  WORKFLOW_EXECUTION_START_TIME TIMESTAMP_TZ DEFAULT CURRENT_TIMESTAMP() /* timestamp (no timezone) */,\n  HOST_NAME TEXT /* host name */,\n  PRIMARY KEY (WORKFLOW_ID, EXECUTION_ID)\n) CLUSTER BY ((WORKFLOW_ID));\n```","height":240,"width":544},"type":"n8n-nodes-base.stickyNote","position":[1168,864],"typeVersion":1,"id":"69f8b8c0-96b7-44bf-ba00-4382799c9d8d","name":"Sticky Note30"},{"parameters":{"workflowId":{"__rl":true,"value":"5fLEtpYDMhJTTEzh","mode":"list","cachedResultUrl":"/workflow/5fLEtpYDMhJTTEzh","cachedResultName":"Insert into Snowflake Table"},"workflowInputs":{"mappingMode":"defineBelow","value":{"save_obj":"={{ $json.save_obj }}","primary_keys":"={{ $json.primary_keys }}","snowflake_table_obj":"={{ $json.snowflake_table_obj }}"},"matchingColumns":[],"schema":[{"id":"save_obj","displayName":"save_obj","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"object","removed":false},{"id":"primary_keys","displayName":"primary_keys","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"array","removed":false},{"id":"snowflake_table_obj","displayName":"snowflake_table_obj","required":false,"defaultMatch":false,"display":true,"canBeUsedToMatch":true,"type":"object","removed":false}],"attemptToConvertTypes":false,"convertFieldsToString":true},"options":{}},"type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[1232,1136],"id":"dfe4fa3f-7d41-46b0-b8f7-d0f7884f68b5","name":"Save Workflow Execution Data"},{"parameters":{"mode":"raw","jsonOutput":"={\n  \"save_obj\": {\n    \"input_object\": {{ $json.body.toJsonString() }},\n    \"execution_id\": {{ $execution.id }},\n    \"workflow_id\": {{ $workflow.id.toJsonString() }},\n    \"workflow_name\": {{ $workflow.name.toJsonString() }},\n    \"workflow_execution_start_time\": \"{{ $now.toString() }}\",\n    \"host_name\": \"https://n8n-relayer-1.app.n8n.cloud\"\n  },\n  \"primary_keys\": [\"workflow_id\", \"execution_id\"],\n  \"snowflake_table_obj\": {{ $json.snowflake_tables.n8n_workflow_executions }}\n}\n","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[1008,1136],"id":"68f32eae-0d32-4065-986e-201cb583f70d","name":"Create Workflow Execution Object"},{"parameters":{"content":"## Save input object","height":336,"width":560,"color":6},"type":"n8n-nodes-base.stickyNote","position":[912,1008],"typeVersion":1,"id":"217865a8-f5fe-4cf0-a616-60184d09c017","name":"Sticky Note31"},{"parameters":{"model":"o4-mini","options":{"responseFormat":"json_object"}},"type":"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi","typeVersion":1,"position":[2960,2848],"id":"253641dc-582e-47bb-82f3-ed1989804094","name":"Topics Agent o4-mini1","credentials":{"azureOpenAiApi":{"id":"N96DE6AiByL8h8kA","name":"Azure Open AI o4-mini"}}},{"parameters":{"content":"## Succcess","height":224,"width":416,"color":4},"type":"n8n-nodes-base.stickyNote","position":[9360,1712],"typeVersion":1,"id":"60906376-fd87-47fd-a5ff-16d2553f9aaf","name":"Sticky Note32"},{"parameters":{"fieldToSplitOut":"document_ids","options":{}},"type":"n8n-nodes-base.splitOut","typeVersion":1,"position":[5472,2544],"id":"769aeba7-c0b8-45ba-831e-b21aee3df805","name":"Split into each document id","onError":"continueRegularOutput"},{"parameters":{"jsCode":"const document_ids_set = new Set($input.first().json.document_ids);\n\n// for (const item of $input.all()) {\n//   document_ids_set.add(item.json.document_ids);\n// }\n\nconst document_ids = [...document_ids_set];\n\nreturn [ { \"document_ids\": document_ids } ];"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[5920,2544],"id":"d5906024-dc56-4388-ba39-d0c831409e52","name":"Unique Set of Document Ids"},{"parameters":{"jsCode":"// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nconsole.log($input.all())\n\nconst document_ids = []\n\nfor (const item of $input.all()) {\n  document_ids.push(...item.json.document_ids);\n}\n\n// return $input.all();\n\nreturn [\n  {\n    \"document_ids\": document_ids\n  }\n];"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[4000,3040],"id":"aa22aa62-fef9-417a-9dc0-f6498d42afc5","name":"Gather Document Ids5","onError":"continueRegularOutput"},{"parameters":{"mode":"raw","jsonOutput":"={\n  \"output\": {\n    \"process_name\": \"topic_document_query_table_search_results\",\n    \"document_ids\": {{ $json.document_ids }}\n  }\n}","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[5264,4032],"id":"9136889d-843d-4ade-8520-0cd8f67e064b","name":"Topic Document Query Table Search Results JSON"},{"parameters":{"mode":"raw","jsonOutput":"={\n  \"output\": {\n    \"process_name\": \"topic_document_query_name_search_results\",\n    \"document_ids\": {{ $json.document_ids }}\n  }\n}\n","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[5264,3824],"id":"eb05c3d1-0e80-4c69-bd1e-856f08df3f2c","name":"Topic Document Query Name Search Results JSON"},{"parameters":{"fieldToSplitOut":"document_ids","options":{}},"type":"n8n-nodes-base.splitOut","typeVersion":1,"position":[6224,2544],"id":"4f7da10d-bb00-45e5-9f92-537b132e7064","name":"For each unique document id"},{"parameters":{"jsCode":"// Input 0 (A): items like { permits: [...], document_id: \"...\" }\n// Input 1 (B): single item like { document_ids: [\"id1\",\"id2\",\"id2\",...]} (may contain duplicates)\n\n// Collect allowed IDs from A\nconst aItems = $input.all();\n\nconst aItemsWithPermits = aItems\n    // .map(i => i.json?.permits)\n  .map(i => i.json)\n  .filter(document_permits_obj => document_permits_obj.permits.length > 0\n   );\n\nconst aItemDocumentIds = aItemsWithPermits.map(item => item.document_id);\n\nconst allowed_set = new Set(\n  aItemDocumentIds\n);\n\nconst allowed = [...allowed_set];\n\n\n\n// Get B list (with possible duplicates)\nconst bItems = $('Split into each document id').all();\n\n// const b_items_document_ids = [];\n\n// for (const item in bItems)\nconst b_items_document_ids = bItems.map(item => item.json.document_ids);\n\nif (!b_items_document_ids.length) {\n  return []; // no B to filter\n}\nconst docIds = Array.isArray(b_items_document_ids) ? b_items_document_ids : [];\n\n\n\n// Keep order and duplicates from B, remove IDs not present in A\nconst filtered = docIds.filter(id => allowed.includes(id));\n\n// Return a single item with the filtered list\nreturn [{ json: { document_ids: filtered } }];\n"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[7104,2544],"id":"f035b941-a47b-4f29-bb16-d55613e5e59c","name":"Filter out non-permits from dupe list"},{"parameters":{"content":"```\n// Input 0 (A): items like { permits: [...], document_id: \"...\" }\n// Input 1 (B): single item like { document_ids: [\"id1\",\"id2\",\"id2\",...]} (may contain duplicates)\n\n// Collect allowed IDs from A\nconst aItems = $input.all();\n\nconst aItemsWithPermits = aItems\n    // .map(i => i.json?.permits)\n  .map(i => i.json)\n  .filter(document_permits_obj => document_permits_obj.permits.length > 0\n   );\n\nconst aItemDocumentIds = aItemsWithPermits.map(item => item.document_id);\n\nconst allowed = new Set(\n  aItemDocumentIds\n);\n\n// Get B list (with possible duplicates)\nconst bItems = $('Split into each document id').all();\n\n// const b_items_document_ids = [];\n\n// for (const item in bItems)\nconst b_items_document_ids = bItems.map(item => item.json.document_ids);\n\nif (!b_items_document_ids.length) {\n  return []; // no B to filter\n}\nconst docIds = Array.isArray(b_items_document_ids) ? b_items_document_ids : [];\n\n// Keep order and duplicates from B, remove IDs not present in A\nconst filtered = docIds.filter(id => allowed.has(id));\n\n// Return a single item with the filtered list\nreturn [{ json: { document_ids: filtered } }];\n```","height":240,"width":560},"type":"n8n-nodes-base.stickyNote","position":[6896,2864],"typeVersion":1,"id":"4f3e450b-8f98-456e-a636-5e9e122320fa","name":"Sticky Note33"},{"parameters":{"content":"### Cortex Search Document by Keyword\n- searches For documents\n- uses document name that is similar to keywords or key concepts extracted from the message"},"type":"n8n-nodes-base.stickyNote","position":[2672,1488],"typeVersion":1,"id":"f1eda748-184b-4285-8bce-486c961098ac","name":"Sticky Note34"},{"parameters":{"content":"## Semantic Search by Given Key Words/Phrases","height":848,"width":1392,"color":6},"type":"n8n-nodes-base.stickyNote","position":[2736,1344],"typeVersion":1,"id":"ac35162c-913c-4e3f-b1dd-37f8d5c3921a","name":"Sticky Note35"},{"parameters":{"content":"```\n# Agent Prompt (RAG-Query String Generator)\n\n## Role\nYou generate the best search strings for a RAG service that is already indexed on query names and dashboard names. Your goal is to return a prioritized, deduplicated list of concise strings that maximize dashboard hits.\n\n## Inputs\n- `topics_metadata_json`: array of { base_view, group_label, description, ai_context, key_words }.\n- `messages`: array of user messages (strings).\n- `top_k_topics`: integer, default 3.\n- `max_queries`: integer, default 6.\n\n<topics_metadata_json>\n{{ $json.toJsonString() }}\n</topics_metadata_json>\n\n<messages>\n{{ $('Body with Filtered User Messages').first().json.body.user_messages.toJsonString() }}\n</messages>\n\n## Objective\nProduce short, high-signal strings that match likely dashboard or saved-query titles. Favor exact phrases users/search owners would name, not full sentences.\n\n## Step-by-Step\n1. **Normalize messages**\n  - Join messages  `query_text` (lowercase). Extract noun phrases and bigrams (e.g., \"discounting by band\", \"pricing committee\", \"deal pricing summary\", \"gtm leads\").\n  - Do **NOT** include the words in any key words or phrases:\n    - Omni\n    - Looker\n    - Dashboard\n\n2. **Topic scoring**\n   - Build topic text per item: base_view + group_label + description + ai_context + key_words.\n   - Expand `key_words` with noun phrases from description/ai_context.\n   - Compute topic score = 0.5 semantic similarity + 0.4 keyword overlap + 0.1 domain hint.\n   - Keep top `top_k_topics`.\n\n3. **Query candidates (per top topic)**\n   - **Exact anchors**: base_view and its spaced form  \n     - e.g., `sales__opportunity`, `sales opportunity`.\n   - **Phrase variants** from messages  topic lexicon (limit to 25 words each):  \n     - e.g., `discounting by band`, `opportunity discount bands`, `deal pricing by band`.\n   - **Entity combos** (title-like):  \n     - `<domain> <measure> <cut>`  `opportunity discount band`, `pricing discount bands`, `deal discount bands`.\n\n\n4. **Synthesize title-like strings**\n   - Combine anchors + phrases into natural dashboard-title candidates (36 tokens):  \n     - `Opportunity Discounting by Band`  \n     - `Deal Pricing by Discount Band`  \n     - `Sales Opportunity Discount Bands`  \n     - `Discounting by Band`  \n     - `GTM Leads Deal Pricing Summary`\n\n5. **Short queries for fuzzy matching**\n   - Emit compact 26 token strings that often appear in titles:  \n     - `discount band`, `opportunity discount`, `deal pricing`, `gtm leads pricing`.\n\n6. **Prioritize and dedupe**\n  - Priority = topic_score boost if string contains base_view alias or domain noun (\"opportunity\", \"deal\").  \n  - Keep unique strings. Trim punctuation. Title case for title-like forms; lowercase for short forms.\n  - Final list must **ONLY** have <max_queries> number of items\n\n7. **Quality checks**\n   - Length 26 tokens unless base_view literal.  \n   - Avoid stopwords and verbose phrasing.  \n   - No quotes, AND/OR, or boolean syntaxonly raw strings.\n\n## Query Templates\n- Anchor-only: `{base_view}`, `{base_view.replace('__',' ')}`\n- Title-like: `{entity} {measure} by {cut}`\n- N-gram: `{measure} {cut}`, `{entity} {measure}`, `{platform} {measure}`\n- Migration: `{platform_old} {measure}`, `{platform_new} {measure}`\n\n## Guidelines\n- Optimize for how dashboards are titled, not how users speak in sentences.\n- Prefer domain nouns: opportunity, deal, pricing, discount, band, leads.\n- Keep queries short and varied to hit exact and partial title matches.\n- Include both neutral and platform-prefixed variants if platforms are mentioned.\n- Order from most precise to most general.\n\n## Output Format\nReturn a JSON object:\n```json\n[\n    \"Deal Pricing by Discount Band\",\n    \"Sales Opportunity Discount Bands\",\n    \"GTM Leads Deal Pricing Summary\",\n    \"gtm leads pricing\",\n    \"sales opportunity\",\n    \"sales__opportunity\"\n  ]\n```\n\n## Example (given the messages)\nMessages mention \"discounting analysis\", \"discounting by band\", \"Pricing Committee\", and \"deal pricing summary in gtm leads\".\n\nSuggested strings (ordered):\n1. Opportunity Discounting by Band\n2. Deal Pricing by Discount Band\n3. Sales Opportunity Discount Bands\n4. Discounting by Band\n6. GTM Leads Deal Pricing Summary\n7. Opportunity Discount Bands\n8. Deal Discount Bands\n9. Opportunity Discounting\n10. Deal Pricing Summary\n11. discount band\n12. opportunity discount\n13. deal pricing\n14. gtm leads pricing\n15. sales opportunity\n16. sales__opportunity\n\n```","height":272,"width":496},"type":"n8n-nodes-base.stickyNote","position":[3344,1136],"typeVersion":1,"id":"353ee004-dacc-4d0d-848a-8b186caa1f82","name":"Sticky Note36"},{"parameters":{"modelName":"models/gemini-2.5-pro","options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatGoogleGemini","typeVersion":1,"position":[2880,1728],"id":"6d141e47-e0fc-4ab8-9b6f-4d28a806733a","name":"Extract Keywords Agent Gemini 2.5 Pro","credentials":{"googlePalmApi":{"id":"LKQbGwmroZKBfciU","name":"Gemini - Cribl"}}},{"parameters":{"schemaType":"manual","inputSchema":"{\n  \"type\": \"integer\"\n}\n"},"type":"@n8n/n8n-nodes-langchain.outputParserStructured","typeVersion":1.3,"position":[3232,1936],"id":"5a181e09-2765-498f-bf0b-6ac0c3ac6e66","name":"ERROR Extract Keywords Agent Structured Output Parser1"},{"parameters":{"schemaType":"manual","inputSchema":"{\n  \"type\": \"array\",\n  \"items\": {\n    \"type\": \"string\"\n  }\n}\n"},"type":"@n8n/n8n-nodes-langchain.outputParserStructured","typeVersion":1.3,"position":[3216,1728],"id":"228ae56b-74b3-4fcd-a520-f4308d4a461c","name":"Extract Keywords Agent Structured Output Parser1"},{"parameters":{"model":"o4-mini","options":{"responseFormat":"text"}},"type":"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi","typeVersion":1,"position":[3040,1808],"id":"d3ca4708-fbab-4474-8d0a-40116963c521","name":"Extract Keywords Agent o4-mini1","credentials":{"azureOpenAiApi":{"id":"N96DE6AiByL8h8kA","name":"Azure Open AI o4-mini"}}},{"parameters":{"mode":"raw","jsonOutput":"{\n  \"opportunity_snapshot\": {\n    \"base_view\": \"sales__opportunity_snapshot\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Daily snapshot of opportunity data to track changes over time, snapshots taken at 11PM PST\",\n    \"ai_context\": \"You are a sales or revenue operations leader focused on pipeline and performance using daily snapshots of Salesforce opportunity data. The opportunity_snapshot model captures the state of each opportunity as of each day, including stage, close date, owner, amount, and new ARR. You use it to analyze how pipeline changes over time, track stage movement, measure in-quarter shifts, and compare pipeline coverage across different dates. This model helps you understand what has progressed, what has stalled or dropped, and how current trends compare to previous quarters, supporting more accurate forecasting and strategic planning.\",\n    \"key_words\": []\n  },\n  \"rep_monthly_leading_indicators\": {\n    \"base_view\": \"leading_indicators\",\n    \"group_label\": \"Sales\",\n    \"description\": \"POVs and NBMs on a Monthly Level by Rep\",\n    \"key_words\": []\n  },\n  \"accounts_snapshot\": {\n    \"base_view\": \"sales__accounts_snapshot\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Daily snapshot of accounts data to track changes over time, snapshot taken at 11PM PST\",\n    \"ai_context\": \"You are a sales, customer success, or revenue operations leader tracking how accounts evolve over time. The accounts_snapshot model captures a daily view of each accounts status, including firmographic details, licensed usage, ARR, strategic flags, and lifecycle metrics like renewals and upsells. You use this model to monitor changes in customer behavior, identify at-risk or high-growth accounts, and analyze trends in engagement or revenue by segment or region. Its essential for time-based reporting, strategic account planning, and measuring the impact of sales and success efforts over time.\",\n    \"key_words\": []\n  },\n  \"activity\": {\n    \"base_view\": \"sales__activity\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Activity information from SFDC which includes meetings, calls, and emails\",\n    \"ai_context\": \"You are a sales or revenue operations leader tracking how reps engage with prospects and customers across the funnel. The sales__activity model captures Salesforce tasks and eventsincluding emails, calls, and meetingsand classifies them by type, direction (inbound, outbound, internal), and associated contacts or accounts. It connects activity data to sales milestones like discovery meetings and enriches it with lead and contact details. You use this model to understand rep productivity, measure engagement across segments or stages, and identify gaps in outreach. It's a key input for pipeline health, activity-based forecasting, and optimizing team performance.\",\n    \"key_words\": []\n  },\n  \"deal_registrations\": {\n    \"base_view\": \"sales__opportunity\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Partner Portal and Tech Alliance Registrations for Deals\",\n    \"ai_context\": \"You are a sales or revenue operations leader focused on partner-driven pipeline and performance using deal registration data. Each registration is tied to a partner and potential opportunity, and includes metadata such as registration type, status, associated opportunity, account, and key dates like registration submission, expected close, and actual close. You use this data to understand how much partner-registered pipeline exists, whats been approved or closed, and how it breaks down by partner, region, or segment. The registrations model unifies historical Salesforce and current Vartopia registration data, enriching it with opportunity and account context. You use it to track registration trends, analyze approval and conversion rates, evaluate partner impact, and identify gaps or delays in the registration lifecycle to better forecast revenue and optimize channel performance.\",\n    \"key_words\": []\n  },\n  \"opportunity\": {\n    \"base_view\": \"sales__opportunity\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Sales Opportunities info with account and use case information\",\n    \"ai_context\": \"You are a sales or revenue operations leader focused on pipeline and performance using Salesforce opportunity data. Each opportunity is tied to a customer and includes metadata such as stage, close date, owner, and amount. The key metric is \\\"new ARR,\\\" which represents the annual recurring revenue expected or won from a deal. You ask questions to understand how much pipeline exists, whats been closed, and how it breaks down by customer, region, segment, or sales rep. Youre also interested in identifying top opportunities, forecasting revenue, and tracking sales performance over time.\\n\\nquestion: What open deal does Cribl have this fiscal quarter?\\nanswer: \\n  {\\n    \\\"limit\\\": 500,\\n    \\\"sorts\\\": [\\n      {\\n        \\\"null_sort\\\": \\\"OMNI_DEFAULT\\\",\\n        \\\"column_name\\\": \\\"sales__opportunity.new_arr_derived\\\",\\n        \\\"is_column_sort\\\": false,\\n        \\\"sort_descending\\\": true\\n      }\\n    ],\\n    \\\"table\\\": \\\"sales__opportunity\\\",\\n    \\\"fields\\\": [\\n      \\\"sales__opportunity.opportunity_name\\\",\\n      \\\"sales__opportunity.new_arr_derived\\\",\\n      \\\"sales__opportunity.stage_name\\\",\\n      \\\"sales__opportunity.close_date[fiscal_quarter]\\\"\\n    ],\\n    \\\"pivots\\\": [],\\n    \\\"dbtMode\\\": false,\\n    \\\"filters\\\": {\\n      \\\"sales__opportunity.is_closed\\\": {\\n        \\\"type\\\": \\\"boolean\\\",\\n        \\\"is_negative\\\": true,\\n        \\\"treat_nulls_as_false\\\": false\\n      },\\n      \\\"sales__opportunity.close_date\\\": {\\n        \\\"kind\\\": \\\"TIME_FOR_UNIT_DURATION\\\",\\n        \\\"type\\\": \\\"date\\\",\\n        \\\"left_side\\\": \\\"this fiscal quarter\\\"\\n      }\\n    },\\n    \\\"modelId\\\": \\\"1b4e2e0b-4868-4f96-b1a1-2896507103a9\\\",\\n    \\\"version\\\": 7,\\n    \\\"rewriteSql\\\": true,\\n    \\\"row_totals\\\": {},\\n    \\\"fill_fields\\\": [],\\n    \\\"calculations\\\": [],\\n    \\\"column_limit\\\": 50,\\n    \\\"join_via_map\\\": {},\\n    \\\"column_totals\\\": {\\n      \\\"::total::\\\": {\\n        \\\"type\\\": \\\"aggregation\\\"\\n      }\\n    },\\n    \\\"userEditedSQL\\\": \\\"\\\",\\n    \\\"dimensionIndex\\\": 0,\\n    \\\"default_group_by\\\": true,\\n    \\\"filtersUsedInSql\\\": null,\\n    \\\"model_extension_id\\\": null,\\n    \\\"custom_summary_types\\\": {},\\n    \\\"join_paths_from_topic_name\\\": \\\"opportunity\\\",\\n    \\\"period_over_period_computations\\\": null\\n  }\\n\",\n    \"key_words\": [\"deal\", \"opportunities\"]\n  },\n  \"pipeline_xray\": {\n    \"base_view\": \"sales__pipeline_xray\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Pipeline xray coverage model\",\n    \"ai_context\": \"You are a sales or revenue operations leader focused on understanding pipeline health across current and future quarters. The pipeline_xray model provides a time-based view of sales opportunitiessegmenting deals by quarter, sales stage, and outcome using daily opportunity snapshots. It helps you track progress in the current quarter, compare against past performance, and forecast future pipeline coverage. Use it to answer questions like How are we pacing this quarter? What does next quarters pipeline look like? Where are the gaps by segment or region? This model supports both daily sales execution and long-range planning.\",\n    \"key_words\": []\n  },\n  \"opportunity_pov_use_cases\": {\n    \"base_view\": \"sales__opportunity\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Opportunity data with POV use cases\",\n    \"ai_context\": \"You are a sales or revenue operations leader focused on tracking and improving proof of value (POV) initiatives. The pov_use_cases model gives you a structured view of POV submissions captured in Salesforce, including use case types, collection methods, and associated product areas. It separates key dimensions like Stream Use Cases, Edge Collection Sources, and Use Case Categories to make analysis easier and more actionable. You use this model to understand which use cases are most common, how POV volume is trending, what teams are involved, and where process improvements are needed. It supports use cases like forecasting POV demand, optimizing enablement efforts, evaluating resource impact, and refining POV strategy to improve conversion and customer fit.\",\n    \"key_words\": [\"support\", \"salesforce case\"]\n  },\n  \"registrations\": {\n    \"base_view\": \"sales__registrations\",\n    \"group_label\": \"Sales\",\n    \"key_words\": []\n  },\n  \"accounts\": {\n    \"base_view\": \"sales__accounts\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Information on all accounts in Salesforce\",\n    \"ai_context\": \"You are a business operations analyst focused on customer account metadata. You care about understanding the composition and distribution of customer accounts. You often need to answer questions like how many accounts exist, how many are active customers, and how they are segmented by region or industru. Your goal is to provide quick insights into customer trends, identify growth areas, and support decision-making with clear, accurate account data.\\n\\nquestion: How many customers does Cribl have?\\n\\nanswer: \\n {\\n   \\\"limit\\\": 1000,\\n   \\\"sorts\\\": [],\\n   \\\"table\\\": \\\"sales__accounts\\\",\\n   \\\"fields\\\": [\\n     \\\"sales__accounts.cribl_id_count_distinct\\\"\\n   ],\\n   \\\"pivots\\\": [],\\n   \\\"dbtMode\\\": false,\\n   \\\"filters\\\": {\\n     \\\"sales__accounts.is_customer\\\": {\\n       \\\"type\\\": \\\"boolean\\\",\\n       \\\"is_negative\\\": false,\\n       \\\"treat_nulls_as_false\\\": false\\n     }\\n   },\\n   \\\"modelId\\\": \\\"257a200a-be61-467c-b9db-4976984fee51\\\",\\n   \\\"version\\\": 7,\\n   \\\"rewriteSql\\\": true,\\n   \\\"row_totals\\\": {},\\n   \\\"fill_fields\\\": [],\\n   \\\"calculations\\\": [],\\n   \\\"column_limit\\\": 50,\\n   \\\"join_via_map\\\": {},\\n   \\\"column_totals\\\": {},\\n   \\\"userEditedSQL\\\": \\\"\\\",\\n   \\\"dimensionIndex\\\": 0,\\n   \\\"default_group_by\\\": true,\\n   \\\"custom_summary_types\\\": {},\\n   \\\"join_paths_from_topic_name\\\": \\\"accounts\\\"\\n }\\n\",\n    \"key_words\": [\"prospects\", \"customers\"]\n  },\n  \"pg_program_spiff\": {\n    \"base_view\": \"pg_program_spiff\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Reporting for the Enterprise pipeline generation program SPIFF\",\n    \"key_words\": []\n  },\n  \"rep_status\": {\n    \"base_view\": \"sales__rep_start_dates\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Non-restricted rep information, excluding ARR and quota attainment\",\n    \"key_words\": []\n  },\n  \"ve_engagement_opportunity\": {\n    \"base_view\": \"sales__opportunity\",\n    \"group_label\": \"Sales\",\n    \"description\": \"Information on all Value Engagements in SFDC\",\n    \"key_words\": []\n  },\n  \"search_activity\": {\n    \"base_view\": \"product__search_activity\",\n    \"group_label\": \"Product\",\n    \"description\": \"Cribl Search activity over time. Breakdown by queries or users\",\n    \"ai_context\": \"You are an engineer or product manager tracking volume and type of\\nqueries made through Cribl's Search product. Each event represents a step in a\\nsearch query such as query queued or completed. Other metadata such as\\nLakehouse usage or status are included to enrich and contextualize each event.\\n\\nKey Concepts:\\nSearch Activity captures detailed user interactions with Cribl Cloud search features.\\n\\nTracks when, how, and by whom searches are performed, along with search duration, success rates, and user engagement trends.\\n\\nPrimary KPIs:\\nNumber of search activities per user, per organization, per day.\\n\\nAverage search duration.\\n\\nSearch success rates and error occurrences.\\n\\nGrowth trends in search adoption over time.\\n\\nData Source:\\nThe search_activity model within the product schema:\\n\\nAggregates data from:\\n\\nSearch logs\\n\\nUser login activity\\n\\nOrganizational profiles\\n\\nApplies key data transformations:\\n\\nResolves missing user data using login records.\\n\\nCleanses non-production and irrelevant logs.\\n\\nFilters out excessively long or noisy log entries.\\n\\nUtilizes incremental updates to maintain data freshness with minimal processing load.\\n\\nBusiness Context:\\nSupports tracking adoption and usage of cloud search services.\\n\\nEnables performance monitoring to detect slow, failed, or error-prone searches.\\n\\nProvides insights to improve user satisfaction, feature usability, and search efficiency.\\n\\nHelps product teams prioritize enhancements to the search infrastructure based on real user behavior and needs.\\n\\nExample AI Use Cases:\\nSummarization: Provide daily, weekly, or monthly summaries of search usage by product, user, or organization.\\n\\nAnomaly Detection: Identify spikes in failed searches, unusually long search durations, or rapid drops in search activity.\\n\\nTrend Detection: Monitor search adoption over time and detect shifts in user search behavior.\\n\\nSegmentation: Analyze search activity by customer segment, organization type, or geographic region.\\n\\nPerformance Insights: Surface slowest or most resource-intensive searches to guide infrastructure optimization.\\n\",\n    \"key_words\": []\n  },\n  \"cloud_worker_configuration\": {\n    \"base_view\": \"product__cloud_worker_config_daily\",\n    \"group_label\": \"Product\",\n    \"description\": \"Details on cloud workers\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to monitor daily cloud performance, track customer usage patterns, and proactively manage cloud resources.\\n\\nKey Concepts:\\nCloud worker configuration daily aggregates worker data by type, configuration, org id, and by date. This dataset tracks the numbers of edge nodes and stream workers.\\n\",\n    \"key_words\": []\n  },\n  \"users_with_completed_searches\": {\n    \"base_view\": \"users_with_completed_searches\",\n    \"group_label\": \"Product\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track user engagement with Cribls cloud search services, specifically focusing on users who have completed searches.\\n\\nKey Concepts:\\nCompleted Searches refer to search interactions that successfully finished within Cribls cloud-based search platform.\\n\\nThis topic focuses on unique users (non-Cribl internal users) who have completed searches, providing insights into search adoption and real-world usage.\\n\\nSearch events must meet the following criteria:\\n\\nThe search was completed successfully.\\n\\nThe user is an external (non-Cribl) user.\\n\\nThe search action is classified as \\\"search finished.\\\"\\n\\nPrimary KPIs:\\nDistinct user counts completing searches per month.\\n\\nSearch activity segmented by organization type.\\n\\nMonthly trends in unique user search completion.\\n\\nData Source:\\nThe search_activity model in the product schema:\\n\\nCentralizes cloud search interaction data.\\n\\nEnriches raw logs with:\\n\\nUser login details.\\n\\nOrganizational context.\\n\\nApplies key filters:\\n\\nExcludes Cribl internal users.\\n\\nFocuses on completed search events.\\n\\nRemoves non-production and irrelevant logs.\\n\\nSupports incremental updates for data freshness.\\n\\nBusiness Context:\\nEnables monitoring of customer adoption and sustained usage of cloud search features.\\n\\nHelps identify highly engaged organizations and user cohorts.\\n\\nSupports product performance tracking and user satisfaction analysis for search functionality.\\n\\nProvides input for customer success efforts, product training prioritization, and infrastructure scaling decisions.\\n\\nExample AI Use Cases:\\nSummarization: Report on the number of distinct users completing searches per month, segmented by organization type.\\n\\nTrend Detection: Identify growth or decline in unique user search completions over time.\\n\\nAnomaly Detection: Surface unusual drops in search activity or unexpected spikes in completion volume.\\n\\nSegmentation: Analyze search adoption patterns by customer type, region, or product cohort.\\n\\nEngagement Scoring: Track active user rates and potential churn indicators based on declining search completions.\\n\",\n    \"key_words\": []\n  },\n  \"cloud_src_dest_segment_monthly\": {\n    \"base_view\": \"cloud_src_dest_segment_monthly\",\n    \"group_label\": \"Product\",\n    \"key_words\": []\n  },\n  \"copilot\": {\n    \"base_view\": \"product__cribl_ai_events_prod\",\n    \"group_label\": \"Product\",\n    \"description\": \"Contains Information on Cribl CoPilot\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track how users interact with Cribls AI-enabled features (Co-Pilot), monitor AI engagement patterns, and analyze user feedback to improve AI performance and user experience.\\n\\nKey Concepts:\\nCo-Pilot refers to Cribls embedded AI capabilities that assist users across products.\\n\\nThe cribl_ai_events_prod dataset captures detailed AI interaction events including user actions, system responses, and direct user feedback.\\n\\nEach event is tied to an organization (org_id) and a specific product environment.\\n\\nPrimary KPIs:\\nNumber of AI interactions per day, per product, per customer.\\n\\nUser engagement rates with Co-Pilot features.\\n\\nUser feedback sentiment and volume.\\n\\nAI usage trends by environment and product.\\n\\nData Source:\\nThe cribl_ai_events_prod model in the product schema:\\n\\nAggregates AI events across multiple platforms and product environments.\\n\\nIntegrates with organizational context from cloud_orgs and cloud_orgs_staging.\\n\\nFilters out internal events and irrelevant user activity to maintain clean, external-facing analytics.\\n\\nStandardizes timestamps and resolves organization identifiers to ensure data completeness.\\n\\nBusiness Context:\\nSupports product-led growth by improving AI-powered user experiences.\\n\\nHelps identify which AI features are most used, underutilized, or generating negative feedback.\\n\\nFacilitates targeted product improvements, AI tuning, and UI enhancements based on real-world user interactions.\\n\\nEnables continuous monitoring of AI performance and customer sentiment.\\n\\nExample AI Use Cases:\\nSummarization: Provide daily, weekly, or monthly summaries of AI feature usage and user feedback.\\n\\nAnomaly Detection: Identify unusual patterns in AI event volume, feedback trends, or low engagement signals.\\n\\nTrend Detection: Track adoption and growth of Co-Pilot features across products and customer segments.\\n\\nSentiment Analysis: Summarize and classify user feedback to assess AI satisfaction and feature effectiveness.\\n\\nSegmentation: Analyze AI usage by organization type, product, or environment to inform targeted improvements.\\n\",\n    \"key_words\": []\n  },\n  \"cloud_telemetry_daily\": {\n    \"base_view\": \"product__cloud_telemetry_daily\",\n    \"group_label\": \"Product\",\n    \"description\": \"Phone home telemetry aggregated daily for Cribl Cloud customers\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to monitor daily cloud performance, track customer usage patterns, and proactively manage cloud resources.\\n\\nKey Concepts:\\nCloud Telemetry provides daily operational data about how organizations interact with Cribl Cloud services.\\n\\nTracks user activity, resource consumption, system throughput, and cloud service performance across customer organizations.\\n\\nEach telemetry record is linked to a specific organization (org_id) and captures data at the daily level.\\n\\nPrimary KPIs:\\nDaily user logins per organization.\\n\\nDaily data throughput (ingested, processed, and sent GBs).\\n\\nDaily compute resource usage.\\n\\nDaily active edge nodes.\\n\\nSystem performance and stability metrics.\\n\\nData Source:\\nThe cloud_telemetry_daily model in the product schema:\\n\\nAggregates raw telemetry data into a structured, daily snapshot.\\n\\nApplies incremental updates to ensure freshness without processing redundant records.\\n\\nCleans, deduplicates, and enriches data with organization and login context from related models like cloud_orgs and cloud_logins.\\n\\nBusiness Context:\\nEnables real-time performance tracking and historical trend analysis.\\n\\nSupports capacity planning, cloud resource optimization, and customer usage monitoring.\\n\\nHelps surface early warnings of system degradation, customer disengagement, or unusual usage patterns.\\n\\nCritical for product-led growth strategies and operational excellence in cloud environments.\\n\\nExample AI Use Cases:\\nSummarization: Generate daily, weekly, or monthly cloud usage and performance summaries.\\n\\nAnomaly Detection: Identify unusual spikes or drops in logins, data throughput, or compute usage.\\n\\nForecasting: Predict future resource requirements based on historical telemetry trends.\\n\\nBehavioral Analysis: Track user engagement levels by analyzing login frequency and system interactions.\\n\\nSegmented Insights: Compare usage patterns across different customer segments, product plans, or organization types.\\n\",\n    \"key_words\": [\"phone home\", \"cloud orgs\", \"cloud\"]\n  },\n  \"invites_monthly\": {\n    \"base_view\": \"product__invite_acceptance_monthly\",\n    \"group_label\": \"Product\",\n    \"description\": \"Contains monthly views on free org invites sent and accepted\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track how and when organizations register for Cribl Cloud services to monitor customer acquisition, onboarding trends, and early adoption behaviors.\\n\\nKey Concepts:\\nThe data is aggregated monthly and contains how many invites are sent, resent, and accepted. This only pertains to free orgs.\\n\\nPrimary KPIs:\\nNumber of invitations sent.\\nNumber of invitations accepted.\\nNumber of invitations resent.\\nNumber of invitations accepted after the resent.\\nConversion rates between invite sent and accepted.\\n\\nBusiness Context:\\nUnderstanding invite acceptance rates helps optimize the signup flow and identify any bottlenecks.\\n\\nExample AI Use Cases:\\n\\nTrend Detection: Identify significant drops in invites sent or accepted\\n\",\n    \"key_words\": []\n  },\n  \"software_edge_nodes_fq\": {\n    \"base_view\": \"software_edge_nodes_fq\",\n    \"group_label\": \"Product\",\n    \"description\": \"software Edge nodes aggregated by Fiscal Quarter\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track and analyze the deployment and usage of on-premises Software Edge Nodes over time to understand customer engagement, product adoption, and infrastructure scaling.\\n\\nKey Concepts:\\nSoftware Edge Nodes represent on-premises nodes used by customers to process data locally via Cribls software.\\n\\nNodes are tracked by fiscal quarter, license, and license type.\\n\\nFocus is specifically on enterprise licenses using client-side telemetry.\\n\\nPrimary KPIs:\\nMaximum number of edge nodes deployed per fiscal quarter.\\n\\nTotal edge nodes aggregated across all customers.\\n\\nUnique license counts and distribution by license type.\\n\\nGrowth trends in on-premises edge node deployment over time.\\n\\nData Source:\\nThe Software Edge Nodes dataset is derived from the onprem_telemetry_daily model in the product schema.\\n\\nKey features:\\n\\nAggregates daily telemetry data from on-premises sources.\\n\\nFilters to client-side telemetry for enterprise licenses.\\n\\nGroups data by fiscal quarter using a date mapping table.\\n\\nData Transformations:\\n\\nCalculates daily and quarterly maximum edge node counts.\\n\\nFilters out non-enterprise license types unless client-side telemetry is present.\\n\\nUses incremental updates to maintain data freshness.\\n\\nBusiness Context:\\nProvides visibility into the scale of on-premises software deployments.\\n\\nSupports trend analysis for product adoption, licensing growth, and infrastructure planning.\\n\\nHelps identify expansion opportunities, underutilized licenses, or potential customer churn risks.\\n\\nInforms tactical operational monitoring and long-term strategic capacity planning.\\n\\nExample AI Use Cases:\\nSummarization: Generate quarterly summaries of edge node deployment by license type and customer segment.\\n\\nTrend Detection: Identify increasing or decreasing deployment trends of software edge nodes over time.\\n\\nAnomaly Detection: Surface unexpected changes in edge node counts or sudden shifts in license activity.\\n\\nSegmentation: Analyze edge node deployment by customer size, industry, or regional segments.\\n\\nForecasting: Predict future on-premises edge node deployments based on historical growth patterns.\\n\",\n    \"key_words\": []\n  },\n  \"use_case_adoption\": {\n    \"base_view\": \"product__use_case_adoption\",\n    \"group_label\": \"Product\",\n    \"description\": \"Monthly view of technical use-case adoption for Cribl Cloud customers.\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to analyze how customers adopt specific Cribl use cases to track technology engagement, identify growth opportunities, and optimize customer success strategies.\\n\\nKey Concepts:\\nUse Case Adoption measures how customers engage with Cribls core technological use cases across cloud environments.\\n\\nAccounts are classified into High Adopter, Low Adopter, and Non-Adopter segments based on usage patterns and cloud credit consumption.\\n\\nAdoption patterns are evaluated at the account level and linked to customer lifecycle stages, cloud telemetry data, and sales opportunities.\\n\\nPrimary KPIs:\\nAdoption status per account: High, Low, or Non-Adopter.\\n\\nCloud credit consumption by use case.\\n\\nAccount engagement trends by use case and customer segment.\\n\\nCorrelation of use case adoption with business outcomes and sales opportunities.\\n\\nData Source:\\nThe use_case_adoption model within the product schema:\\n\\nIntegrates data from:\\n\\nSales opportunities\\n\\nCloud telemetry\\n\\nCloud organizations\\n\\nAccount usage statistics\\n\\nKey Transformations:\\n\\nAggregates cloud credit consumption and operational metrics.\\n\\nTracks opportunity lifecycle stages.\\n\\nSegments accounts by adoption level using defined thresholds.\\n\\nCorrelates adoption with buying centers and deployment scenarios.\\n\\nBusiness Context:\\nEnables targeted upsell and cross-sell strategies based on use case adoption levels.\\n\\nSupports customer segmentation for tailored enablement and support.\\n\\nHelps product teams prioritize features and enhancements aligned with customer adoption trends.\\n\\nInforms resource allocation and success planning by identifying growth-ready accounts or accounts at risk of low engagement.\\n\\nExample AI Use Cases:\\nSummarization: Generate summaries of use case adoption by customer segment, product, or industry.\\n\\nTrend Detection: Identify emerging use cases and growing adoption patterns across accounts.\\n\\nAnomaly Detection: Surface unexpected drops or surges in use case adoption within specific accounts or segments.\\n\\nSegmentation: Analyze adoption trends by adopter type (High, Low, Non-Adopter) to inform engagement strategies.\\n\\nForecasting: Predict future use case adoption based on historical cloud credit consumption and opportunity progression.\\n\",\n    \"key_words\": []\n  },\n  \"software_telemetry_daily\": {\n    \"base_view\": \"product__onprem_telemetry_daily\",\n    \"group_label\": \"Product\",\n    \"description\": \"Phone home telemetry aggregated daily for Software customers\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to monitor daily system activity, product usage, and operational performance for Cribls on-premises software customers.\\n\\nKey Concepts:\\nOn-Prem Telemetry Daily is Cribls daily phone-home telemetry dataset that captures detailed system usage metrics from on-premises customer environments.\\n\\nTelemetry includes bytes in/out, events processed, edge node activity, and source/destination segmentation.\\n\\nData is reported at the GUID level and partitioned by license and telemetry method.\\n\\nPrimary KPIs:\\nDaily bytes processed (in and out).\\n\\nDaily events processed (stream and edge).\\n\\nActive edge node counts.\\n\\nEdge dropped bytes and dropped events.\\n\\nDaily product utilization by customer and license type.\\n\\nData Source:\\nThe onprem_telemetry_daily model in the product schema:\\n\\nAggregates telemetry data from customer systems daily.\\n\\nIntegrates source and destination segmentation from the onprem_src_and_dest_daily model.\\n\\nApplies key transformations:\\n\\nFilters for client-side telemetry and enterprise licenses to maintain data relevance.\\n\\nUses incremental updates to efficiently process new and updated records.\\n\\nProvides cleaned and structured telemetry ready for business analysis.\\n\\nBusiness Context:\\nSupports daily operational monitoring, system performance tracking, and product adoption analysis.\\n\\nEnables forecasting of system demand and infrastructure scaling requirements.\\n\\nHelps identify underutilization, customer disengagement, or system health concerns.\\n\\nProvides strategic insights for product planning, licensing adjustments, and customer success initiatives.\\n\\nExample AI Use Cases:\\nSummarization: Provide daily, weekly, or monthly summaries of system usage, product activity, and edge node deployment.\\n\\nAnomaly Detection: Identify unexpected spikes or drops in data volume, edge node counts, or dropped events.\\n\\nTrend Detection: Monitor long-term trends in on-premises product adoption and system utilization.\\n\\nSegmentation: Analyze telemetry patterns by customer segment, license type, or telemetry method.\\n\\nForecasting: Predict future system loads, storage needs, and resource requirements based on historical telemetry patterns.\\n\",\n    \"key_words\": []\n  },\n  \"cloud_registrations\": {\n    \"base_view\": \"product__cloud_registrations\",\n    \"group_label\": \"Product\",\n    \"description\": \"Contains info on users signing up for Cloud and accepting invitations\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track how and when organizations register for Cribl Cloud services to monitor customer acquisition, onboarding trends, and early adoption behaviors.\\n\\nKey Concepts:\\nCloud Registration represents the moment when an organization creates or activates a Cribl Cloud account, typically via a user sign-up or an accepted invitation.\\n\\norg_id is the unique identifier that links registration events to specific organizations.\\n\\nPrimary KPIs:\\nNumber of new cloud registrations over time.\\n\\nNumber of invitations accepted.\\n\\nConversion rates from invitation to active registration.\\n\\nRegistration trends by customer segment or source.\\n\\nData Source:\\nThe Cloud Registrations dataset is sourced from:\\n\\ninvitation_accepted events.\\n\\nsigned_up events.\\n\\nThese records are linked via:\\n\\nevent_id: Identifies the specific user event.\\n\\nemail: Captures the registering user.\\n\\norg_id: Links the user registration to a customer organization.\\n\\nBusiness Context:\\nUnderstanding registration trends is critical for tracking customer acquisition and evaluating marketing or product-led growth initiatives.\\n\\nRegistrations are an early indicator of customer intent and help forecast future product adoption and engagement.\\n\\nExample AI Use Cases:\\nSummarization: Report total cloud registrations by month, quarter, or customer segment.\\n\\nTrend Detection: Identify peaks in registration activity aligned with product launches, marketing campaigns, or sales pushes.\\n\\nAnomaly Detection: Detect unusual drops or spikes in registration activity.\\n\\nSegmentation: Analyze registrations by organization type, geography, or source (invitation vs. direct sign-up).\\n\\nConversion Tracking: Measure conversion rates from invitations sent to successful sign-ups.\\n\",\n    \"key_words\": []\n  },\n  \"feature_adoption\": {\n    \"base_view\": \"product__feature_adoption\",\n    \"group_label\": \"Product\",\n    \"description\": \"Adoption of Features within our Cloud Product\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track, analyze, and optimize how customers adopt and engage with Cribl product features over time.\\n\\nKey Concepts:\\nFeature Adoption tracks when and how organizational users interact with specific product features, especially after new releases.\\n\\nThe dataset helps identify popular, underutilized, and emerging features to inform product strategy, customer outreach, and training initiatives.\\n\\nPrimary KPIs:\\nFeature adoption counts per organization.\\n\\nTime-to-adoption from feature release.\\n\\nEngagement trends by feature category or user segment.\\n\\nComparison of feature adoption across product releases.\\n\\nData Source:\\nThe feature_adoption model within the product schema:\\n\\nCombines data from:\\n\\ncloud_telemetry: Tracks real-time feature usage.\\n\\nsearch_audit_logs: Captures detailed search and interaction events.\\n\\nUses feature transformation dictionaries to:\\n\\nDefine feature names, categories, and release dates.\\n\\nSpecify measurement logic (e.g., counts, max values).\\n\\nApplies incremental updates for efficient, near-real-time reporting.\\n\\nBusiness Context:\\nEnables product teams to understand which features are driving customer value.\\n\\nSupports targeted enablement, customer training, and marketing campaigns for underused features.\\n\\nHelps prioritize feature enhancements, bug fixes, and future product investments.\\n\\nFacilitates customer segmentation by adoption patterns to guide personalized success strategies.\\n\\nExample AI Use Cases:\\nSummarization: Generate feature adoption summaries by product, release, customer segment, or time period.\\n\\nTrend Detection: Identify features with rapidly increasing or declining adoption rates.\\n\\nAnomaly Detection: Highlight features that are not being adopted as expected post-release.\\n\\nSegmentation: Compare adoption patterns across different customer types, organization sizes, or industries.\\n\\nForecasting: Predict feature adoption trajectories based on historical usage patterns.\\n\",\n    \"key_words\": []\n  },\n  \"ending_customers\": {\n    \"base_view\": \"product__ending_customers\",\n    \"group_label\": \"Product\",\n    \"description\": \"Ending Customer Counts per Product\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track customer engagement lifecycles, identify when product usage has ended, and proactively address customer churn risk.\\n\\nKey Concepts:\\nEnding Customers are accounts where product usage has significantly declined or fully stopped, signaling potential churn.\\n\\nCustomers are classified as:\\n\\nActive: Consistent product usage.\\n\\nNon-Adopter: Product purchased but never actively used.\\n\\nInactive: Product usage has stopped based on defined inactivity thresholds.\\n\\nPrimary KPIs:\\nFirst and last recorded product adoption dates per customer.\\n\\nCustomer engagement status (Active, Non-Adopter, Inactive).\\n\\nDuration between initial purchase and last meaningful product usage.\\n\\nCloud search activity and other product interactions as engagement signals.\\n\\nData Source:\\nThe ending_customers model in the product schema:\\n\\nCombines data from:\\n\\nopportunity: Captures product purchase timelines.\\n\\naccounts: Provides account-level details.\\n\\nadoption: Tracks product usage activity.\\n\\nKey Transformations:\\n\\nCalculates first and last adoption dates.\\n\\nEvaluates whether usage meets minimum activity benchmarks.\\n\\nCategorizes customer engagement levels based on activity timelines and purchase history.\\n\\nBusiness Context:\\nEnables early identification of disengaged customers for customer success outreach.\\n\\nSupports sales renewal planning and churn mitigation efforts.\\n\\nProvides insights for targeted re-engagement campaigns and product adoption strategies.\\n\\nHelps product teams understand friction points in the customer journey and feature adoption lifecycle.\\n\\nExample AI Use Cases:\\nSummarization: Generate monthly summaries of customer status by engagement category (Active, Non-Adopter, Inactive).\\n\\nTrend Detection: Monitor trends in customer lifecycle transitions and early signs of disengagement.\\n\\nAnomaly Detection: Identify sudden drops in customer usage that may require immediate intervention.\\n\\nSegmentation: Analyze disengagement patterns by product, region, or customer type.\\n\\nRetention Forecasting: Predict churn likelihood based on historical usage, engagement timelines, and inactivity signals.\\n\",\n    \"key_words\": []\n  },\n  \"adoption\": {\n    \"base_view\": \"product__adoption\",\n    \"group_label\": \"Product\",\n    \"description\": \"Contains info on Product Adoption for both Software and Cloud products\",\n    \"ai_context\": \"You are a Product Manager, Customer Success Manager, or Business Leader at Cribl. Your goal is to understand how customers are adopting Cribls product portfolio over time. Cribl follows a land and expand growth strategy, where increasing the number of products used by each customer is a key business objective.\\n\\nKey Concepts:\\nProduct Adoption is measured by product usage volume (bytes processed or billed credits) and unique product count per customer over time.\\nThe primary KPI is the number of unique Cribl products adopted per customer.\\n  \\nAdditional KPIs include: bytes processed, credits billed, active nodes, completed searches, edge processing metrics, and storage in data lakes.\\n\\nData Source:\\nThe primary dataset is the adoption model within the product schema. It combines on-premises and cloud product usage to create a customer-level, 30-day rolling average view of adoption.\\n\\nKey data sources include:\\n\\naccounts\\n\\nonprem_src_and_dest_daily\\n\\nlicenses\\n\\nonprem_telemetry_daily\\n\\ncloud_billing_daily\\n\\ncloud_telemetry_daily\\n\\nBusiness Context:\\nCustomers are expected to adopt more products and increase usage over time.\\n\\nTracking adoption trends helps identify expansion opportunities, customer health risks, and underutilized features.\\n\\nThis information supports product roadmap decisions, customer success initiatives, and targeted marketing campaigns.\\n\\nExample AI Use Cases:\\nIdentifying customers with declining product adoption.\\n\\nSurfacing customers ready for cross-sell based on multi-product usage.\\n\\nHighlighting trends in on-premises vs. cloud adoption patterns.\\n\",\n    \"key_words\": []\n  },\n  \"cloud_orgs_and_billing\": {\n    \"base_view\": \"product__cloud_orgs\",\n    \"group_label\": \"Product\",\n    \"description\": \"Contains information on cloud orgs and billing metrics from metronome\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track cloud customer organizations, understand their cloud service engagement, and monitor detailed billing and usage patterns over time.\\n\\nKey Concepts:\\nCloud Orgs represent customer accounts using Cribl Cloud services, each tied to specific sales opportunities, service plans, and cloud credit allocations.\\n\\nCloud Billing tracks daily resource consumption at the organization level, including data transfer volumes and compute usage.\\n\\nCloud Orgs Model\\nPurpose:\\nProvides a consolidated customer view combining cloud account details, service plans, credit usage, telemetry data, and Salesforce sales opportunities.\\n\\nTracks account status (active, expired, internal, or customer-facing) and monitors how cloud credits are consumed.\\n\\nPrimary KPIs:\\nCredit balance and usage per organization.\\n\\nNumber of active cloud organizations.\\n\\nSales opportunity alignment with cloud usage trends.\\n\\nBusiness Context:\\nSupports customer success, sales pipeline management, and cloud service forecasting.\\n\\nHelps identify expansion opportunities and monitor customer adoption health.\\n\\nEnables account segmentation by status, credit utilization, and engagement level.\\n\\nCloud Billing Daily Model\\nPurpose:\\nProvides a daily snapshot of cloud resource consumption across all cloud organizations.\\n\\nTracks metrics like:\\n\\nGigabytes (GBs) sent and received.\\n\\nCompute resource usage.\\n\\nData ingestion and egress by service type and worker group.\\n\\nPrimary KPIs:\\nDaily GBs sent and received per organization.\\n\\nDaily compute usage.\\n\\nCloud resource consumption trends.\\n\\nBusiness Context:\\nSupports real-time tracking, cost management, and anomaly detection in cloud usage.\\n\\nProvides insights to optimize cloud resource allocation, prevent overages, and detect spikes.\\n\\nEnables proactive cloud capacity and cost forecasting.\\n\\nExample AI Use Cases:\\nSummarization: Monthly customer usage and billing trends.\\n\\nAnomaly Detection: Unusual spikes in data transfer, compute usage, or credit consumption.\\n\\nForecasting: Predict future cloud credit depletion or resource usage based on historical patterns.\\n\\nSegmentation: Identify cloud organizations by usage tier, growth trajectory, or account status.\\n\\nRisk Identification: Surface customers with high credit burn rates or low resource engagement.\\n\",\n    \"key_words\": [\"cloud credits\"]\n  },\n  \"cloud_edge_nodes_monthly\": {\n    \"base_view\": \"cloud_edge_nodes_monthly\",\n    \"group_label\": \"Product\",\n    \"description\": \"Monthly Cloud Edge Nodes\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Business Leader at Cribl. You need to understand how customers are using edge nodes in Cribl Cloud over time.\\n\\nKey Concepts:\\nEdge Nodes represent Cribl processing nodes deployed in the cloud to manage and route customer data.\\n\\nTracking the number of active edge nodes per customer per month is critical for understanding cloud resource utilization, customer growth, and performance scaling.\\n\\nPrimary KPIs:\\nTotal Edge Nodes per Month per Customer (org_id)\\n\\nDistinct number of active customers using edge nodes each month.\\n\\nSummed edge node counts across all customers for trend analysis.\\n\\nData Source:\\nThe cloud_edge_nodes_monthly dataset in the product schema provides a monthly summary of the maximum number of edge nodes in use per organization.\\n\\nIt is derived from the cloud_telemetry_daily table, which:\\n\\nAggregates daily cloud telemetry data.\\n\\nTracks key performance indicators like resource usage, data throughput, and system activity.\\n\\nIs incrementally updated for efficiency and freshness.\\n\\nBusiness Context:\\nCustomers typically increase edge node usage over time as they scale.\\n\\nUnderstanding edge node trends helps forecast capacity, track customer engagement, and identify potential over- or under-utilization.\\n\\nInsights support product development, customer success, and cloud infrastructure planning.\\n\\nExample AI Use Cases:\\nTrend Detection: Identify customers who are rapidly scaling edge node usage.\\n\\nAnomaly Detection: Highlight unusual spikes or drops in edge node counts.\\n\\nForecasting: Predict future edge node consumption to support cloud capacity planning.\\n\\nSummarization: Provide monthly overviews of edge node adoption across customer segments.\\n\",\n    \"key_words\": []\n  },\n  \"org_cleanup_notifications\": {\n    \"base_view\": \"product__org_cleanup_notifications\",\n    \"group_label\": \"Product\",\n    \"description\": \"Contains notifications and metrics related to Cribl cloud org clean up process\",\n    \"ai_context\": \"You are an engineer or finance manager looking to understand how many orgs were sent purge notifications, orgs that were purged, and the AWS cost savings.\\n\",\n    \"key_words\": []\n  },\n  \"cloud_user_invites\": {\n    \"base_view\": \"product__cloud_user_invites\",\n    \"group_label\": \"Product\",\n    \"description\": \"Contains Cribl Cloud invitation data\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track how and when organizations register for Cribl Cloud services to monitor customer acquisition, onboarding trends, and early adoption behaviors.\\n\\nKey Concepts:\\nNumber of invitations sent.\\nNumber of invitations accepted.\\nConversion rates between invite sent and accepted.\\n\\nBusiness Context:\\nUnderstanding invite acceptance rates helps optimize the signup flow and identify any bottlenecks.\\n\\nExample AI Use Cases:\\n\\nTrend Detection: Identify significant drops in invites sent or accepted\\n\",\n    \"key_words\": []\n  },\n  \"cloud_credits_line_items\": {\n    \"base_view\": \"product__cloud_credits_line_items\",\n    \"group_label\": \"Product\",\n    \"description\": \"Monthly Cloud Credit Usage at Line-item level via Metronome. Break down usage by Customer, Product (Search, Infrastructure, etc.), & Billable Metric (GBs Received, etc.). All usage in credits, not dollars.\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Business Leader at Cribl. You need to understand how cloud credits are applied and consumed across customer invoices to manage financial health, track credit utilization, and support customer success.\\n\\nKey Concepts:\\nCloud Credits are pre-allocated billing units provided to customers to cover cloud product usage.\\n\\nThis model tracks how, when, and where cloud credits are applied to individual invoices across both finalized and pending billing periods.\\n\\nCredits are typically applied to services like Search Subscription, Lakehouse, and other Cribl cloud offerings.\\n\\nPrimary KPI:\\nCloud Credit Consumption per Service per Customer per Invoice\\n\\nSecondary KPIs include: unit pricing, billed amounts, remaining credits, and the distinction between finalized and pending invoices.\\n\\nData Source:\\nThe cloud_credits_line_items model within the product schema provides a line-level view of cloud credit transactions.\\n\\nIt integrates data from:\\n\\nMonthly Cloud Grants\\n\\nCustomer Account Details\\n\\nItemized Billing Line Items\\n\\nBusiness Context:\\nEnables transparency into how cloud credits are consumed at a detailed level.\\n\\nSupports forecasting credit burn, managing overages, and ensuring proper credit allocation.\\n\\nProvides insights into billing trends, credit application efficiency, and customer-specific consumption patterns.\\n\\nExample AI Use Cases:\\nIdentifying customers who are at risk of running out of cloud credits.\\n\\nHighlighting unusual credit consumption patterns or billing anomalies.\\n\\nForecasting future credit consumption based on historical usage trends.\\n\\nSummarizing total cloud credit consumption by product, service type, or customer segment.\\n\",\n    \"key_words\": []\n  },\n  \"software_gb_monthly\": {\n    \"base_view\": \"software_gb_monthly\",\n    \"group_label\": \"Product\",\n    \"description\": \"Contains information on in / out gb estimated monthly and source/destination segmentation\",\n    \"ai_context\": \"You are a Product Manager, Engineering Manager, Technical Program Manager, or Company Leader at Cribl. You need to track and analyze the volume of data processed through Cribls on-premises software edge nodes and streaming pipelines, segmented by source and destination, on a monthly basis.\\n\\nKey Concepts:\\nSoftware GB Monthly summarizes monthly data throughput (in and out) and edge node activity from Cribls on-premises environments.\\n\\nTracks stream and edge data volumes in gigabytes (GB) and terabytes (TB), along with associated events and dropped data.\\n\\nSegments data by streaming pipelines and edge nodes to differentiate between direct and edge processing paths.\\n\\nPrimary KPIs:\\nEstimated monthly stream data in and out (GB/TB).\\n\\nEstimated monthly edge data in and out (GB/TB).\\n\\nMonthly dropped bytes and events.\\n\\nMaximum edge nodes active per month.\\n\\nTotal data events processed monthly.\\n\\nData Source:\\nThe Software GB Monthly dataset is derived from the onprem_telemetry_daily model within the product schema.\\n\\nKey Transformations:\\n\\nAggregates telemetry data by month, license, and license type.\\n\\nCalculates averages and maximums across daily records.\\n\\nFilters to client-side telemetry for enterprise licenses to maintain data accuracy.\\n\\nApplies incremental updates for efficient, up-to-date reporting.\\n\\nDetailed Segmentation:\\n\\nData is split between streaming sources/destinations and edge nodes.\\n\\nAdditional metrics capture data dropped at the edge and the number of associated events.\\n\\nBusiness Context:\\nProvides deep visibility into customer data processing volumes across on-premises environments.\\n\\nSupports forecasting, capacity planning, and licensing decisions.\\n\\nEnables identification of customers with heavy or growing data processing needs.\\n\\nHelps detect underutilization, data drops, or anomalies in expected processing volumes.\\n\\nExample AI Use Cases:\\nSummarization: Generate monthly summaries of in/out data volumes and edge node activity by license or customer segment.\\n\\nTrend Detection: Identify increasing or decreasing data volume trends across edge nodes and streaming pipelines.\\n\\nAnomaly Detection: Surface unusual spikes or drops in data throughput, dropped bytes, or edge node counts.\\n\\nSegmentation: Analyze processing volume patterns by license type, customer size, or telemetry method.\\n\\nForecasting: Predict future storage, bandwidth, and processing needs based on historical data volume trends.\\n\",\n    \"key_words\": []\n  },\n  \"Packs_usage_telemetry\": {\n    \"base_view\": \"product__packs_telemetry\",\n    \"group_label\": \"Product\",\n    \"description\": \"Contains info on Packs usage over time at the Org level.\",\n    \"ai_context\": \"You are a Product Manager, Customer Success Manager, or Business Leader at Cribl. Your goal is to understand how customers are adopting and using \\nCribls packs product.\\n\",\n    \"key_words\": []\n  },\n  \"cloud_edge_nodes_fq\": {\n    \"base_view\": \"cloud_edge_nodes_fq\",\n    \"group_label\": \"Product\",\n    \"key_words\": []\n  },\n  \"journey_reports\": {\n    \"base_view\": \"customerx__journey_reports\",\n    \"group_label\": \"CustomerX\",\n    \"description\": \"Information on Customers 30/60/90-Day Onboarding Journey Reports\",\n    \"key_words\": []\n  },\n  \"monthly_utilization_consumption\": {\n    \"base_view\": \"customerx__monthly_utilization_consumption\",\n    \"group_label\": \"CustomerX\",\n    \"description\": \"Monthly view of Utilization and Consumption for our customer base\",\n    \"key_words\": [\"utilization\",\"consumption\",\"pacing\"]\n  },\n  \"ps_projects\": {\n    \"base_view\": \"services__ps_projects\",\n    \"group_label\": \"CustomerX\",\n    \"description\": \"Details on PS Projects via Mavenlink\",\n    \"key_words\": [\"services\",\"onboarding\"]\n  },\n  \"case_csat\": {\n    \"base_view\": \"support__csat_survey\",\n    \"group_label\": \"Support\",\n    \"description\": \"CSAT related to cases\",\n    \"ai_context\": \"The csat_survey model within the support schema offers a centralized and standardized view of customer satisfaction feedback collected from multiple channels, including Google Sheets and Survey Monkey. When exploring this model, you can easily analyze how customers feel about their support experiencestracking key indicators like issue resolution success, satisfaction scores, and qualitative comments. The model connects survey responses directly to support cases and contacts, allowing you to drill into feedback at both the case and customer level. Use this data to uncover trends in satisfaction, identify pain points in your support process, and measure the impact of improvements over time. Whether you're evaluating team performance or prioritizing enhancements, this model empowers you with actionable insights to elevate customer experience and drive loyalty.\",\n    \"key_words\": []\n  },\n  \"case_milestones\": {\n    \"base_view\": \"support__milestones\",\n    \"group_label\": \"Support\",\n    \"description\": \"Log of all case milestones & SLAs\",\n    \"ai_context\": \"The milestones model in the support schema gives customer support teams a clear, detailed view of the key steps and deadlines in each cases lifecycle. By tracking milestone start, target, and completion datesalong with whether milestones are completed or violatedthis model helps you monitor case progress against commitments. It ties milestone details directly to case information, making it easy to see the full story behind each support interaction. Use this model to quickly identify cases at risk of missing important deadlines, understand time remaining or overdue per milestone, and hold the right owners accountable. These insights enable proactive case management, helping you prioritize efforts, improve response times, and keep customers satisfied. Whether managing daily workloads or analyzing overall team performance, the milestones data provides actionable clarity to drive faster resolutions and stronger service delivery.\",\n    \"key_words\": []\n  },\n  \"cases_snapshot\": {\n    \"base_view\": \"support__cases_snapshot\",\n    \"group_label\": \"Support\",\n    \"description\": \"Daily snapshot of SFDC cases\",\n    \"ai_context\": \"You are a customer support engineer. This model gives you a clear, detailed view of all your support casesfrom opening to resolution. It shows key info like contacts, accounts, issue details, and how fast cases are responded to and closed. Spam and duplicates are filtered out so you see only real cases. Use it to track your workload, find slow spots, and improve how quickly you help customers. Its your daily tool to stay on top of cases and deliver great support.\",\n    \"key_words\": []\n  },\n  \"cases\": {\n    \"base_view\": \"support__cases\",\n    \"group_label\": \"Support\",\n    \"description\": \"Dig into support case tickets and CSAT score\",\n    \"ai_context\": \"You are a customer support engineer. This model gives you a clear, detailed view of all your support casesfrom opening to resolution. It shows key info like contacts, accounts, issue details, and how fast cases are responded to and closed. Spam and duplicates are filtered out so you see only real cases. Use it to track your workload, find slow spots, and improve how quickly you help customers. Its your daily tool to stay on top of cases and deliver great support.\",\n    \"key_words\": []\n  },\n  \"escalations\": {\n    \"base_view\": \"support__escalations\",\n    \"group_label\": \"Support\",\n    \"description\": \"Details related to support case escalations\",\n    \"ai_context\": \"You are a customer support engineer. This model gives you a clear view of all escalated cases that need extra attention. It links escalations to accounts and cases, showing reasons, status, and timelines so you understand whats happening from start to finish. It helps you track who owns each escalation, how long its been open, and spot delays early. Use it to manage escalations efficiently, improve response times, and keep customers happy by resolving critical issues quickly.\",\n    \"key_words\": []\n  },\n  \"case_backlog\": {\n    \"base_view\": \"case_backlog\",\n    \"group_label\": \"Support\",\n    \"description\": \"Weekly log of opened cases\",\n    \"ai_context\": \"You are a support operations analyst monitoring the weekly backlog of open support cases. The case_backlog model tracks cases from their opened week through to closure, excluding duplicates, spam, merged cases, tests, and non-support records. It cross-joins case data with calendar weeks to generate a weekly snapshot of active cases, linking case IDs, numbers, owners, and managers. This enables teams to analyze case aging, backlog trends, and workload distribution over time, supporting effective resource planning and backlog reduction efforts.\",\n    \"key_words\": []\n  },\n  \"case_assists\": {\n    \"base_view\": \"support__case_assists\",\n    \"group_label\": \"Support\",\n    \"description\": \"Details on case assists\",\n    \"ai_context\": \"You are a customer support manager or analyst tracking collaborative efforts in case resolution. The case_assists model captures instances where helpers (non-owners) contribute to solving support cases by extracting detailed assistance interactions from Salesforce. It excludes cases where the assistant is also the owner, links assists to case details, and translates IDs and timestamps into readable names and dates. This model highlights individual contributions beyond case ownership, providing visibility into teamwork, enabling recognition, improving process insights, and supporting optimized resource allocation for enhanced customer service performance.\",\n    \"key_words\": []\n  },\n  \"employees\": {\n    \"base_view\": \"people__employees\",\n    \"group_label\": \"People\",\n    \"description\": \"Information about Cribl's Employees (Active and Terminated)\",\n    \"ai_context\": \"You are an HR analyst, recruiter, or people leader looking to understand team structures, tenure, and headcount composition. The employees model provides a unified view of all current and future employees, including job title and departments.\",\n    \"key_words\": []\n  },\n  \"content_activity\": {\n    \"base_view\": \"marketing__enablement_content_activity\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Activity related to Seismic content views and sends\",\n    \"ai_context\": \"You are a marketing or enablement analyst focused on understanding how internal content is used. You work with data on documents, presentations, and other materials shared via platforms like Seismic. You ask questions about which content is viewed, how often, by whom, and how usage varies by role, department, or product. Your goal is to track engagement, measure content effectiveness, and improve enablement strategy through data-driven insights.\",\n    \"key_words\": []\n  },\n  \"web_analytics\": {\n    \"base_view\": \"marketing__web_analytics\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Google Analytics 4 events, GA4 was implemented starting in Nov 2022; events before this time are in universal analytics\",\n    \"ai_context\": \"You are a digital marketing or analytics professional seeking insights into website user behavior and traffic performance. This model structures raw web event data into actionable metrics like traffic sources, session details, user engagement, and navigation patterns. It enables detailed analysis of how different channels drive visits and conversions, helping optimize campaigns and improve the user experience. Daily updates ensure the data is current for timely decision-making.\",\n    \"key_words\": []\n  },\n  \"training_progress\": {\n    \"base_view\": \"marketing__enablement_training_progress\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"RSM and SDR Seismic onboarding activity leading up to full productivity\",\n    \"ai_context\": \"You are a learning and development leader focused on tracking and improving employee training engagement and outcomes. This model provides detailed visibility into training assignments, progress, completion status, and overdue flags across departments. It tracks key milestones and time spent per session to measure effectiveness and identify gaps in learning adoption. With daily updates, it supports timely interventions and strategic planning to enhance workforce development and to optimize training programs.\",\n    \"key_words\": []\n  },\n  \"public_relations_metrics\": {\n    \"base_view\": \"marketing__public_relations_metrics\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Public Relations Metrics tracking Media Mentions, Updated Weekly\",\n    \"ai_context\": \"You are a marketing or communications professional focused on assessing the impact of public relations efforts. This model consolidates data on PR coverageincluding media type, outlet, publication date, and content qualityto measure the reach and effectiveness of each PR activity. By scoring and categorizing PR entries, it provides insights into which media placements and messages drive brand awareness and reputation. This enables strategic optimization of PR campaigns to maximize visibility and align with business goals. The model is ideal for non-technical stakeholders seeking clear, actionable summaries of PR performance.\",\n    \"key_words\": []\n  },\n  \"leads_and_contacts_snapshot\": {\n    \"base_view\": \"marketing__leads_and_contacts_snapshot\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Daily snapshot of leads/contacts funnel to track changes over time\",\n    \"ai_context\": \"You are a marketing or sales analyst focused on leads and contacts from Salesforce over time. You work with snapshot data that tracks individuals as leads, contacts, or both, capturing their statuses, conversion dates, sources, and engagement milestones at specific points in time. You ask questions to analyze trends in lead quality, contact engagement, and pipeline contribution across different dates. Your goal is to monitor changes over time to optimize marketing attribution, prioritize leads, and improve sales handoff with time-aware insights into the customer journey.\",\n    \"key_words\": []\n  },\n  \"slack_metrics\": {\n    \"base_view\": \"marketing__slack_metrics\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Cribl community slack metrics aggregated daily, this does not include details on Cribl's internal slack.\",\n    \"ai_context\": \"\",\n    \"key_words\": []\n  },\n  \"leads_and_contacts\": {\n    \"base_view\": \"marketing__leads_and_contacts\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Info on Leads/Contacts and their conversion through the marketing funnel / use of sandbox\",\n    \"ai_context\": \"You are a marketing or sales analyst focused on leads and contacts from Salesforce. You work with data that identifies individuals as leads, contacts, or both, including their statuses, conversion dates, sources, and engagement milestones. You ask questions to track lead quality, monitor contact engagement, and understand how these profiles contribute to pipeline growth. Your goal is to optimize marketing attribution, prioritize high-potential leads, and improve sales handoff through clear insights into the customer journey.\",\n    \"key_words\": [\"leads\",\"contacts\"]\n  },\n  \"community_engagement\": {\n    \"base_view\": \"marketing__community_engagement\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Contains weekly metrics on LinkedIn, Twitter, media mentions, and Appscope slack channel/github star\",\n    \"ai_context\": \"You are a marketing analyst focused on tracking community growth and engagement. You work with weekly data on follower counts and memberships across platforms like LinkedIn, Twitter, and other community portals. You ask questions to understand trends in audience growth, brand presence, and campaign impact on community engagement. Your goal is to monitor reach, evaluate marketing effectiveness, and inform community strategy with up-to-date metrics.\",\n    \"key_words\": []\n  },\n  \"criblu_courses\": {\n    \"base_view\": \"marketing__criblu_courses\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Cribl University courses information\",\n    \"ai_context\": \"You are a marketing or learning analyst focused on course enrollment and certification. You work with data on user progress, course categories, completion status, and certifications within Cribls LMS. You ask questions to understand course uptake, user engagement, and certification outcomes by role or department. Your goal is to measure learning effectiveness, support personalized follow-up, and optimize educational content strategy.\",\n    \"key_words\": []\n  },\n  \"marketing_attribution_engaged_by_fq\": {\n    \"base_view\": \"marketing_attribution_engaged_by_fq\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Engaged Marketing Attribution by FQ\",\n    \"key_words\": []\n  },\n  \"linkedin_page\": {\n    \"base_view\": \"marketing__linkedin_page\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Daily aggregation of Cribl's LinkedIn page including engagement and follower metrics\",\n    \"ai_context\": \"You are a marketing analyst focused on LinkedIn page performance and engagement. You work with daily data on follower counts, page interactions, and content effectiveness. You ask questions to understand follower growth, interaction trends, and campaign impact on LinkedIn. Your goal is to optimize content strategy, measure digital presence, and forecast future engagement based on historical and current data.\",\n    \"key_words\": []\n  },\n  \"marketing_attribution\": {\n    \"base_view\": \"marketing__marketing_attribution\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Marketing touchpoint attribution from bizible\",\n    \"ai_context\": \"You are a marketing analyst focused on attributing revenue and opportunities to marketing touchpoints across channels. You work with data linking campaigns, leads, and sales outcomes to measure marketing impact. You ask questions to understand which campaigns and channels drive pipeline and revenue, how touchpoints contribute across the buyers journey, and where to allocate marketing resources for maximum ROI. Your goal is to provide precise, data-driven attribution insights that optimize marketing performance and revenue growth.\",\n    \"key_words\": [\"MQO\",\"AQO\"]\n  },\n  \"linkedin_posts\": {\n    \"base_view\": \"marketing__linkedin_posts\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Aggregate engagement metrics for Cribl LinkedIn posts\",\n    \"ai_context\": \"You are a marketing or social media analyst focused on LinkedIn content performance. You work with data on post typesorganic, sponsored, repostsand their engagement metrics like likes, shares, and comments. You ask questions to understand which posts drive the most interaction, how different content types perform, and how to optimize content strategy. Your goal is to maximize reach, improve engagement, and measure ROI of LinkedIn campaigns.\",\n    \"key_words\": []\n  },\n  \"campaign\": {\n    \"base_view\": \"marketing__campaign\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Track marketing campaign performance and ROI\",\n    \"ai_context\": \"You are a marketing analyst focused on campaign performance and planning. You work with data on campaign names, types, owners, dates, costs, budgets, channels, and engagement. You ask questions to understand which campaigns ran, how they performed, how much was spent, and which channels or regions were most effective. Your goal is to track ROI through attribution, optimize spend, and improve future campaign strategy.\",\n    \"key_words\": []\n  },\n  \"criblu_sessions\": {\n    \"base_view\": \"marketing__criblu_sessions\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Cribl University session information\",\n    \"key_words\": []\n  },\n  \"pipeline_generation\": {\n    \"base_view\": \"sales__pipeline_generation\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Pipeline Generation Model FY2026\",\n    \"ai_context\": \"You are a sales or marketing leader focused on pipeline generation and performance tracking. This model helps you compare weekly and quarterly sales targets against actual opportunities created, segmented by region, market segment, and opportunity type. You use this data to monitor sales effectiveness, identify performance gaps, and optimize resource allocation. You ask questions about how pipeline creation aligns with targets, where sales and marketing efforts are succeeding or falling short, and how trends evolve over time to improve forecasting and strategic planning across the funnel.\",\n    \"key_words\": []\n  },\n  \"opp_creation_marketing_attribution\": {\n    \"base_view\": \"sales__opportunity\",\n    \"group_label\": \"Marketing\",\n    \"description\": \"Marketing Attribution for Opportunities using Opportunity Creation Attribution\",\n    \"ai_context\": \"You are a marketing operations leader focused on pipeline performance and marketing attribution using Salesforce opportunity data. Each opportunity links to customer and marketing touchpoints, with metadata like stage, close date, owner, and amount. The key metric is \\\"new ARR,\\\" representing expected or won recurring revenue. You ask questions to understand how marketing efforts influence opportunity creation and progression, how pipeline breaks down by marketing channels, campaigns, customer segments, and sales reps. Youre also interested in identifying which marketing activities drive the most qualified opportunities, forecasting revenue influenced by marketing, and tracking how marketing and sales align throughout the funnel to optimize conversion and growth.\",\n    \"key_words\": []\n  },\n  \"quarterly_arr\": {\n    \"base_view\": \"finance__quarterly_arr\",\n    \"group_label\": \"Finance\",\n    \"description\": \"Quarterly ARR by SFDC account and opportunity\",\n    \"key_words\": []\n  },\n  \"product_arr\": {\n    \"base_view\": \"finance__product_arr\",\n    \"group_label\": \"Finance\",\n    \"description\": \"Product ARR rolled up to the SFDC Account level\",\n    \"key_words\": []\n  },\n  \"customer_quarterly_arr\": {\n    \"base_view\": \"finance__customer_quarterly_arr\",\n    \"group_label\": \"Finance\",\n    \"description\": \"Quarterly ARR rolled up to the Customer level\",\n    \"key_words\": []\n  },\n  \"cloud_revenue\": {\n    \"base_view\": \"finance__cloud_revenue\",\n    \"group_label\": \"Finance\",\n    \"description\": \"Cloud ARR rolled up to the SFDC Account level\",\n    \"key_words\": []\n  },\n  \"jira_issues\": {\n    \"base_view\": \"engineering__jira_issues\",\n    \"group_label\": \"Engineering\",\n    \"description\": \"Details on Jira issues and the components, sprints, labels, and versions associate with each issue\",\n    \"ai_context\": \"You are an engineering team lead tracking the progress of development work through Jira issues. Each issue represents a unit of work such as a feature, bug, or task, and includes metadata like status, assignee, priority, labels, and timestamps for when work started or was completed. You ask questions to understand how work is progressing, identify bottlenecks, track developer workload, and ensure that high-priority issues are moving forward.\\n\",\n    \"key_words\": [\"bugs\",\"epics\",\"stories\",\"points\",\"cfd\"]\n  },\n  \"incidents\": {\n    \"base_view\": \"engineering__incidents\",\n    \"group_label\": \"Engineering\",\n    \"description\": \"Details on firehydrant incidents and when they were created and resolved at\",\n    \"key_words\": []\n  },\n  \"cfd_backlog\": {\n    \"base_view\": \"cfd_backlog\",\n    \"group_label\": \"Engineering\",\n    \"description\": \"Monthly Backlog of JIRA tickets directly related to Customer Issues (Has an association to a Support Case or Opportunity in SFDC).\",\n    \"key_words\": []\n  },\n  \"aws_cloud_costs\": {\n    \"base_view\": \"engineering__cloud_cost_daily\",\n    \"group_label\": \"Engineering\",\n    \"description\": \"Details on spend associated with AWS\",\n    \"ai_context\": \"You are a cost analyst, engineer, or finance partner focused on managing AWS spend. The cloud_cost_daily model delivers daily cloud cost data sourced from AWS billing via the cloud_cost base model. It tracks detailed cost types (e.g., Spot, Savings Plans, Reserved), usage metrics, and service-specific charges, with incremental updates to ensure timely, efficient reporting. Costs are enriched via joins with aws_account_map to reflect organizational structure and environment tagging. This model powers granular spend analysis, enabling savings opportunity identification, budget tracking, and cloud governance at both operational and strategic levels.\",\n    \"key_words\": [\"cloud cost daily\"]\n  },\n  \"slo_monthly\": {\n    \"base_view\": \"engineering__slo_workspace_monthly\",\n    \"group_label\": \"Engineering\",\n    \"description\": \"Monthly aggregate for SLO metrics\",\n    \"ai_context\": \"You are a cloud operations leader, engineering manager, or SRE responsible for tracking service reliability across customer-facing infrastructure. This model provides a monthly roll-up of workspace-level SLO performance, helping you understand availability trends and proactively manage service health. You use it to identify which workspaces or customer orgs are breaching or trending toward breaching service level objectivestypically availability thresholds like 99.9%. It supports long-term planning, executive reporting, and prioritization of reliability work. The model joins with organizational data to give you visibility not only into the performance of specific services but also into how those services impact key customers or segments.\",\n    \"key_words\": []\n  },\n  \"azure_cloud_costs\": {\n    \"base_view\": \"engineering__azure_cloud_cost\",\n    \"group_label\": \"Engineering\",\n    \"description\": \"Details on spend associated with Azure cloud services\",\n    \"ai_context\": \"You are a finance analyst, engineer, or cost manager focused on Azure cloud spend. The azure_cloud_cost model aggregates actual, amortized, and adjustment billing data to deliver a unified view of Azure expenses. It joins with azure_account_map to enrich cost data with organizational context like environment type (e.g., dev, staging). Key calculations include retail vs. negotiated costs, effective pricing after discounts, and savings plan utilization. With incremental updates, the model supports near-real-time analysis of spend patterns, enabling proactive budgeting, optimization, and financial accountability across cloud environments.\",\n    \"key_words\": []\n  },\n  \"authentication\": {\n    \"base_view\": \"engineering__authentication_logs\",\n    \"group_label\": \"Engineering\",\n    \"description\": \"Logs of authentication events (auth0)\",\n    \"ai_context\": \"You are an engineer trying to understand how our authentication workflows are performing. This topic covers all auth0 authentication event logs that help measure KPIs, and help understand and triage areas of issues. Some example KPIs are elapsed times to authenticate, failed login attempts by user, and password reset counts.\",\n    \"key_words\": []\n  },\n  \"slo_daily\": {\n    \"base_view\": \"engineering__slo_daily\",\n    \"group_label\": \"Engineering\",\n    \"description\": \"Details on SLO for customer orgs\",\n    \"ai_context\": \"You are a reliability engineer or engineering leader responsible for daily monitoring of service performance against SLOs. The slo_daily model provides a granular, day-by-day view of availability, sourced from JSON-based cloud metrics and enriched with organizational context from cloud_orgs. Each record reflects the available and unavailable minutes per service, categorized by role (leader/worker) and aligned to specific accounts and workspaces. You use this model to detect SLO breaches early, track daily error budgets, and assess service reliability across different organizational units for timely operational decisions.\",\n    \"key_words\": []\n  }\n}","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[2416,1488],"id":"d7c85003-96a7-4bf2-b6b5-ece40c573708","name":"Topics JSON"},{"parameters":{"jsCode":"const input = $input.first();\nconst user_messages =\n  input.json.body.thread_conversation_text.split(\"\\\\n#__--__#\\\\n\");\ninput.json.body.user_messages = user_messages;\nreturn [input];"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[1360,1488],"id":"b8c99c35-47b8-446f-a5a1-89723b5c5ea6","name":"Split Thread Conversation Text"},{"parameters":{"fieldToSplitOut":"output","options":{}},"type":"n8n-nodes-base.splitOut","typeVersion":1,"position":[3440,1488],"id":"9b8fa176-6d0e-40ba-8474-07e74ad343aa","name":"Split into each document id from key words"},{"parameters":{"fieldToSplitOut":"output","options":{}},"type":"n8n-nodes-base.splitOut","typeVersion":1,"position":[3424,2560],"id":"7817eda6-2958-4e59-9150-580b693676a4","name":"Split into each document id from topic","onError":"continueRegularOutput"},{"parameters":{"content":"### TODO\n- have ai summarize conversation to cut out fluff \n- only extract from finalized convo"},"type":"n8n-nodes-base.stickyNote","position":[2592,1776],"typeVersion":1,"id":"b711eff1-1462-444d-90f4-85d579f6c568","name":"Sticky Note28","disabled":true},{"parameters":{"jsCode":"// Loop over input items and add a new field called 'myNewField' to the JSON of each one\n\nconst extracted_keywords = []\n\nfor (const item of $('Split into each document id from key words').all()) {\n  extracted_keywords.push(item.json.output);\n}\n\nconst omni_picked_topics = []\n\nfor (const item of $('Split into each document id from topic').all()) {\n  omni_picked_topics.push(item.json.output);\n}\n\nreturn {\n  \"extracted_keywords\": extracted_keywords,\n  \"omni_picked_topics\": omni_picked_topics\n};"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[6960,3248],"id":"d0f5dcfd-9d2c-47f3-938d-8eb770c1cefc","name":"Get keywords and topics"},{"parameters":{"jsonSchemaExample":"[\n  {\n    \"document_id\": \"959cb1c9\",\n    \"owner_name\": \"John McGuire\",\n    \"owner_id\": \"86a545a6-5958-43e5-8f16-68eb9f148744\",\n    \"document_scope\": \"organization\",\n    \"document_name\": \"Team: SDR Manager\",\n    \"folder_name\": \"Marketing\",\n    \"folder_id\": \"3089bcee-baea-45af-8613-63077f0e9417\",\n    \"has_dashboard\": true,\n    \"folder_path\": \"marketing\",\n    \"count\": 3\n  }\n]"},"type":"@n8n/n8n-nodes-langchain.outputParserStructured","typeVersion":1.3,"position":[8304,3008],"id":"7cdd0733-0b99-4e1e-b4c7-ff5a59ae45b6","name":"Map Reduce Document Structured Output Parser","disabled":true},{"parameters":{"jsCode":"const documents = $input.first().json.output;\nconst documentCounts = documents.reduce((acc, document) => {\n  const documentId = document.document_id;\n  if (!acc[documentId]) {\n    acc[documentId] = { ...document, count: 0 };\n  }\n  acc[documentId].count += 1;\n  return acc;\n}, {});\n\nconst result = Object.values(documentCounts);\nconsole.log(result)\n\n\n// return result.map((item) => ({ json: item }));\n\nreturn [{\"output\": result}]\n"},"type":"n8n-nodes-base.code","typeVersion":2,"position":[8192,2544],"id":"eb6cfb65-4a2b-47b6-89a5-da3cc059b6d8","name":"Map Reduce Document Counts"},{"parameters":{"model":"gpt-4","options":{"responseFormat":"text"}},"type":"@n8n/n8n-nodes-langchain.lmChatAzureOpenAi","typeVersion":1,"position":[2880,1936],"id":"64814f40-69de-4353-a891-3fb90ad31140","name":"Extract Keywords Agent gpt","credentials":{"azureOpenAiApi":{"id":"nBB3SsSM4Tq7RNAe","name":"Azure OpenAI gpt-4"}}},{"parameters":{"mode":"raw","jsonOutput":"={{ $json }}","options":{}},"type":"n8n-nodes-base.set","typeVersion":3.4,"position":[1920,1488],"id":"6556bda2-55a9-4909-97aa-457b7322ee36","name":"Body with Split User Messages"},{"parameters":{"promptType":"define","text":"=## Role\nYou generate the best search strings for a RAG service that is already indexed on query names and dashboard names. Your goal is to return a prioritized, deduplicated list of concise strings that maximize dashboard hits.\n\n## Inputs\n- `topics_metadata_json`: array of { base_view, group_label, description, ai_context, key_words }.\n- `messages`: array of user messages (strings).\n- `top_k_topics`: integer, default 4.\n\n\n<topics_metadata_json>\n{{ $json.toJsonString() }}\n</topics_metadata_json>\n\n<messages>\n{{ $('Body with Split User Messages').first().json.body.user_messages.toJsonString() }}\n</messages>\n\n## Objective\nProduce short, high-signal strings that match likely dashboard or saved-query titles. Favor exact phrases users/search owners would name, not full sentences.\n\n## Step-by-Step\n1. **Normalize messages**\n  - Join messages  `query_text` (lowercase). Extract noun phrases and bigrams (e.g., \"discounting by band\", \"pricing committee\", \"deal pricing summary\", \"gtm leads\").\n  - Do **NOT** include the words in any key words or phrases:\n    - Omni\n    - Looker\n    - Dashboard\n\n2. **Topic scoring**\n   - Build topic text per item: base_view + group_label + description + ai_context + key_words.\n   - Expand `key_words` with noun phrases from description/ai_context.\n   - Compute topic score = 0.5 semantic similarity + 0.4 keyword overlap + 0.1 domain hint.\n   - Keep top `top_k_topics`.\n\n3. **Query candidates (per top topic)**\n   - **Exact anchors**: base_view and its spaced form  \n     - e.g., `sales__opportunity`, `sales opportunity`.\n   - **Phrase variants** from messages  topic lexicon (limit to 25 words each):  \n     - e.g., `discounting by band`, `opportunity discount bands`, `deal pricing by band`.\n   - **Entity combos** (title-like):  \n     - `<domain> <measure> <cut>`  `opportunity discount band`, `pricing discount bands`, `deal discount bands`.\n\n\n4. **Synthesize title-like strings**\n   - Combine anchors + phrases into natural dashboard-title candidates (36 tokens):  \n     - `Opportunity Discounting by Band`  \n     - `Deal Pricing by Discount Band`  \n     - `Sales Opportunity Discount Bands`  \n     - `Discounting by Band`  \n     - `GTM Leads Deal Pricing Summary`\n\n5. **Short queries for fuzzy matching**\n   - Emit compact 26 token strings that often appear in titles:  \n     - `discount band`, `opportunity discount`, `deal pricing`, `gtm leads pricing`.\n\n6. **Prioritize and dedupe**\n  - Priority = topic_score boost if string contains base_view alias or domain noun (\"opportunity\", \"deal\").  \n  - Keep unique strings. Trim punctuation. Title case for title-like forms; lowercase for short forms.\n  - Final list must **ONLY** have `top_k_topics` number of items\n\n7. **Quality checks**\n   - Length 26 tokens unless base_view literal.  \n   - Avoid stopwords and verbose phrasing.  \n   - No quotes, AND/OR, or boolean syntaxonly raw strings.\n\n## Query Templates\n- Anchor-only: `{base_view}`, `{base_view.replace('__',' ')}`\n- Title-like: `{entity} {measure} by {cut}`\n- N-gram: `{measure} {cut}`, `{entity} {measure}`, `{platform} {measure}`\n- Migration: `{platform_old} {measure}`, `{platform_new} {measure}`\n\n## Guidelines\n- Optimize for how dashboards are titled, not how users speak in sentences.\n- Prefer domain nouns: opportunity, deal, pricing, discount, band, leads.\n- Keep queries short and varied to hit exact and partial title matches.\n- Include both neutral and platform-prefixed variants if platforms are mentioned.\n- Order from most precise to most general.\n\n## Output Format\nReturn a JSON object:\n```json\n[\n    \"Deal Pricing by Discount Band\",\n    \"Sales Opportunity Discount Bands\",\n    \"GTM Leads Deal Pricing Summary\",\n    \"gtm leads pricing\",\n    \"sales opportunity\",\n    \"sales__opportunity\"\n  ]\n```\n\n## Example (given the messages)\nMessages mention \"discounting analysis\", \"discounting by band\", \"Pricing Committee\", and \"deal pricing summary in gtm leads\".\n\nSuggested strings (ordered):\n1. Opportunity Discounting by Band\n2. Deal Pricing by Discount Band\n3. Sales Opportunity Discount Bands\n4. Discounting by Band\n6. GTM Leads Deal Pricing Summary\n7. Opportunity Discount Bands\n8. Deal Discount Bands\n9. Opportunity Discounting\n10. Deal Pricing Summary\n11. discount band\n12. opportunity discount\n13. deal pricing\n14. gtm leads pricing\n15. sales opportunity\n16. sales__opportunity\n","hasOutputParser":true,"needsFallback":true,"options":{"systemMessage":"You are an expert data analyst who has built many dashboards in the Omni Analytics tool, which is a business intelligence tool, that sits on top of Snowflake data through dbt. You triage natural language queries from stakeholders within the company in order to find the best dashboard (otherwise known as document) to answer the question. Documents, also known as dashboards, are parents of document queries, which are individual queries that run against the data within the parent document. Metadata on the documents and document queries and document query filters are stored in Snowflake and can be accessed through the Cortex Search Service and the Cortex Analyst tools."}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":2.2,"position":[2992,1488],"id":"98b8e7ba-4259-432d-82fd-c41dbe66c21d","name":"Extract Key Words Agent"}],"connections":{"Webhook":{"main":[[{"node":"Global Vars","type":"main","index":0}]]},"Response Agent":{"main":[[{"node":"Send Slack Success Message","type":"main","index":0},{"node":"Merge Recommendation Agent with Process Results","type":"main","index":0}],[{"node":"Call Slack Error","type":"main","index":0}]]},"Response Agent o4-mini":{"ai_languageModel":[[{"node":"Response Agent","type":"ai_languageModel","index":0}]]},"Response Agent Gemini 2.5 Pro":{"ai_languageModel":[[{"node":"Response Agent","type":"ai_languageModel","index":1}]]},"Response Agent Structured Output Parser":{"ai_outputParser":[[{"node":"Response Agent","type":"ai_outputParser","index":0}]]},"Map Reduce Document Count":{"main":[[]]},"Merge1":{"main":[[{"node":"Split into each document id","type":"main","index":0}]]},"Get Documents with Duplicates (multiple output)":{"main":[[{"node":"Aggregate Documents","type":"main","index":0}]]},"Aggregate Documents":{"main":[[{"node":"Map Reduce Document Counts","type":"main","index":0}]]},"Map Reduce Agent Gemini 2.5 Pro":{"ai_languageModel":[[{"node":"Map Reduce Document Count","type":"ai_languageModel","index":1}]]},"Find Count for Event ID":{"main":[[{"node":"If","type":"main","index":0}]]},"If":{"main":[[{"node":"Retrieve Mapped Object","type":"main","index":0}]]},"Retrieve Mapped Object":{"main":[[{"node":"Insert Recommendation into Snowflake","type":"main","index":0}]]},"Send Slack Success Message":{"main":[[]]},"Map Feedback to Snowflake Schema":{"main":[[{"node":"Find Count for Event ID","type":"main","index":0},{"node":"Call 'Insert into Snowflake Table'","type":"main","index":0}]]},"Insert Table Schema Mapping":{"main":[[{"node":"Map Feedback to Snowflake Schema","type":"main","index":0}]]},"Global Vars":{"main":[[{"node":"Create Workflow Execution Object","type":"main","index":0},{"node":"Split Thread Conversation Text","type":"main","index":0}]]},"Get Document Permissions for User Id":{"main":[[{"node":"Merge Permits and Document Ids","type":"main","index":0}]]},"Merge Permits and Document Ids":{"main":[[{"node":"Filter out no permissions documents","type":"main","index":0}]]},"Filter out no permissions documents":{"main":[[{"node":"Filter out non-permits from dupe list","type":"main","index":0}]]},"Aggregate Document Ids":{"main":[[{"node":"Unique Set of Document Ids","type":"main","index":0}]]},"Keyword Document Name Search Results JSON":{"main":[[{"node":"Merge","type":"main","index":0}]]},"Keyword Document Query Name Search Results JSON":{"main":[[{"node":"Merge","type":"main","index":1}]]},"Keyword Document Query Table Search Results JSON":{"main":[[{"node":"Merge","type":"main","index":2}]]},"Topic Document Search Results JSON":{"main":[[{"node":"Merge","type":"main","index":3}]]},"Merge":{"main":[[{"node":"Aggregate","type":"main","index":0}]]},"Aggregate":{"main":[[{"node":"Get keywords and topics","type":"main","index":0}]]},"Process Metadata":{"main":[[{"node":"Merge Recommendation Agent with Process Results","type":"main","index":1}]]},"Insert recommended_document_ids with Process Results":{"main":[[{"node":"Insert Table Schema Mapping","type":"main","index":0}]]},"Merge Recommendation Agent with Process Results":{"main":[[{"node":"Aggregate to Single Object","type":"main","index":0}]]},"Aggregate to Single Object":{"main":[[{"node":"Insert recommended_document_ids with Process Results","type":"main","index":0}]]},"Response Agent Structured Output Parser1":{"ai_outputParser":[[]]},"Cortex Document Name Search":{"main":[[{"node":"Gather Document Ids2","type":"main","index":0}]]},"Cortex Document Query Name Search":{"main":[[{"node":"Gather Document Ids3","type":"main","index":0}]]},"Cortex Document Query Table Search":{"main":[[{"node":"Gather Document Ids4","type":"main","index":0}]]},"Cortex Document Name Search1":{"main":[[{"node":"Gather Document Ids1","type":"main","index":0}]]},"Cortex Document Query Name Search1":{"main":[[{"node":"Gather Document Ids","type":"main","index":0}]]},"Cortex Document Query Table Search1":{"main":[[{"node":"Gather Document Ids5","type":"main","index":0}]]},"Gather Document Ids":{"main":[[{"node":"Merge1","type":"main","index":4},{"node":"Topic Document Query Name Search Results JSON","type":"main","index":0}]]},"Gather Document Ids1":{"main":[[{"node":"Merge1","type":"main","index":3},{"node":"Topic Document Search Results JSON","type":"main","index":0}]]},"Gather Document Ids2":{"main":[[{"node":"Keyword Document Name Search Results JSON","type":"main","index":0},{"node":"Merge1","type":"main","index":0}]]},"Gather Document Ids3":{"main":[[{"node":"Keyword Document Query Name Search Results JSON","type":"main","index":0},{"node":"Merge1","type":"main","index":1}]]},"Gather Document Ids4":{"main":[[{"node":"Keyword Document Query Table Search Results JSON","type":"main","index":0},{"node":"Merge1","type":"main","index":2}]]},"Omni Pick Topic Tool":{"ai_tool":[[{"node":"Topics Agent","type":"ai_tool","index":0}]]},"Topics Agent":{"main":[[{"node":"Split into each document id from topic","type":"main","index":0}]]},"Topics Agent Gemini 2.5 Pro":{"ai_languageModel":[[{"node":"Topics Agent","type":"ai_languageModel","index":0}]]},"Topics Agent gpt-4":{"ai_languageModel":[[]]},"Deduplicated Topics Structured Output":{"ai_outputParser":[[{"node":"Topics Agent","type":"ai_outputParser","index":0}]]},"Map Reduce Agent o4-mini4":{"ai_languageModel":[[{"node":"Map Reduce Document Count","type":"ai_languageModel","index":0}]]},"Create Workflow Execution Object":{"main":[[{"node":"Save Workflow Execution Data","type":"main","index":0}]]},"Topics Agent o4-mini1":{"ai_languageModel":[[{"node":"Topics Agent","type":"ai_languageModel","index":1}]]},"Split into each document id":{"main":[[{"node":"Aggregate Document Ids","type":"main","index":0}]]},"Unique Set of Document Ids":{"main":[[{"node":"For each unique document id","type":"main","index":0}]]},"Topic Document Query Name Search Results JSON":{"main":[[{"node":"Merge","type":"main","index":4}]]},"Gather Document Ids5":{"main":[[{"node":"Topic Document Query Table Search Results JSON","type":"main","index":0},{"node":"Merge1","type":"main","index":5}]]},"Topic Document Query Table Search Results JSON":{"main":[[{"node":"Merge","type":"main","index":5}]]},"For each unique document id":{"main":[[{"node":"Get Document Permissions for User Id","type":"main","index":0}]]},"Filter out non-permits from dupe list":{"main":[[{"node":"Get Documents with Duplicates (multiple output)","type":"main","index":0}]]},"Extract Keywords Agent Gemini 2.5 Pro":{"ai_languageModel":[[{"node":"Extract Key Words Agent","type":"ai_languageModel","index":0}]]},"Extract Keywords Agent Structured Output Parser1":{"ai_outputParser":[[{"node":"Extract Key Words Agent","type":"ai_outputParser","index":0}]]},"Extract Keywords Agent o4-mini1":{"ai_languageModel":[[{"node":"Extract Key Words Agent","type":"ai_languageModel","index":1}]]},"Save Workflow Execution Data":{"main":[[]]},"Topics JSON":{"main":[[{"node":"Extract Key Words Agent","type":"main","index":0}]]},"Split Thread Conversation Text":{"main":[[{"node":"Body with Split User Messages","type":"main","index":0}]]},"Split into each document id from key words":{"main":[[{"node":"Cortex Document Name Search","type":"main","index":0},{"node":"Cortex Document Query Name Search","type":"main","index":0},{"node":"Cortex Document Query Table Search","type":"main","index":0}]]},"Split into each document id from topic":{"main":[[{"node":"Cortex Document Name Search1","type":"main","index":0},{"node":"Cortex Document Query Name Search1","type":"main","index":0},{"node":"Cortex Document Query Table Search1","type":"main","index":0}]]},"Get keywords and topics":{"main":[[{"node":"Process Metadata","type":"main","index":0}]]},"Map Reduce Document Structured Output Parser":{"ai_outputParser":[[{"node":"Map Reduce Document Count","type":"ai_outputParser","index":0}]]},"Map Reduce Document Counts":{"main":[[{"node":"Response Agent","type":"main","index":0}]]},"Body with Split User Messages":{"main":[[{"node":"Topics JSON","type":"main","index":0},{"node":"Topics Agent","type":"main","index":0}]]},"Extract Key Words Agent":{"main":[[{"node":"Split into each document id from key words","type":"main","index":0}]]}},"settings":{"executionOrder":"v0","callerPolicy":"workflowsFromSameOwner","errorWorkflow":"RMfcJExZ0DdXdMnJ"},"staticData":null,"meta":{"templateCredsSetupCompleted":true},"pinData":{"Webhook":[{"json":{"headers":{"host":"n8n-relayer-1.app.n8n.cloud","user-agent":"Zapier","content-length":"5729","accept":"*/*","accept-encoding":"gzip, br","authorization":"Basic emFwaWVyOldNRXY4NDlmcGZGVlpYNkdoQjM2MGFmT3JmMWtfRFF2TlhfOFRSSjEzS1U=","cdn-loop":"cloudflare; loops=1; subreqs=1","cf-connecting-ip":"3.85.8.196","cf-ew-via":"15","cf-ipcountry":"US","cf-ray":"988eda5223cbc9b1-IAD","cf-visitor":"{\"scheme\":\"https\"}","cf-worker":"n8n.cloud","content-type":"application/json; charset=utf-8","x-forwarded-for":"3.85.8.196, 172.68.245.75","x-forwarded-host":"n8n-relayer-1.app.n8n.cloud","x-forwarded-port":"443","x-forwarded-proto":"https","x-forwarded-server":"traefik-prod-users-gwc-72-585f59b6c7-kgpvq","x-is-trusted":"yes","x-real-ip":"3.85.8.196"},"params":{},"query":{},"body":{"channel_id":"C0912AANW1L","channel_name":"data-eng-test-ai-channel","conversation_id":"C0912AANW1L","event_id":"1759519800.009800","event_timestamp":"2025-10-03T19:30:00.009Z","is_message_user_bot":"False","message_text":"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere","message_thread_ts":"1759516155.914209","message_thread_ts_time":"2025-10-03T18:29:15.000Z","message_timestamp":"2025-10-03T18:29:15.914Z","message_ts":"1759516155.914209","message_user_email":"pgupta@cribl.io","message_user_first_name":"Priya","message_user_id":"U02CBV3GSM9","message_user_last_name":"Gupta","message_user_name":"priya_gupta","reaction":"omni","reaction_user_email":"nkwok@cribl.io","reaction_user_id":"U06PVBEK9T6","team_domain":"cribl","team_id":"T3XQYAF26","thread_conversation_text":"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere \\n#__--__#\\nThe `Slack Error` workflow with execution id <https://n8n-relayer-1.app.n8n.cloud/workflow/RMfcJExZ0DdXdMnJ/executions/4840|4840> has failed with the following body input:\n```{\n  \"channel_id\": \"C0912AANW1L\",\n  \"channel_name\": \"data-eng-test-ai-channel\",\n  \"conversation_id\": \"C0912AANW1L\",\n  \"event_id\": \"1759516158.007800\",\n  \"event_timestamp\": \"2025-10-03T18:29:18.007Z\",\n  \"is_message_user_bot\": \"False\",\n  \"message_text\": \"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\",\n  \"message_thread_ts\": \"1759516155.914209\",\n  \"message_thread_ts_time\": \"2025-10-03T18:29:15.000Z\",\n  \"message_timestamp\": \"2025-10-03T18:29:15.914Z\",\n  \"message_ts\": \"1759516155.914209\",\n  \"message_user_email\": \"<mailto:pgupta@cribl.io|pgupta@cribl.io>\",\n  \"message_user_first_name\": \"Priya\",\n  \"message_user_id\": \"U02CBV3GSM9\",\n  \"message_user_last_name\": \"Gupta\",\n  \"message_user_name\": \"priya_gupta\",\n  \"reaction\": \"omni\",\n  \"reaction_user_email\": \"<mailto:pgupta@cribl.io|pgupta@cribl.io>\",\n  \"reaction_user_id\": \"U02CBV3GSM9\",\n  \"team_domain\": \"cribl\",\n  \"team_id\": \"T3XQYAF26\",\n  \"thread_conversation_text\": \"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\"\n}``` \\n#__--__#\\nThe `Slack Error` workflow with execution id <https://n8n-relayer-1.app.n8n.cloud/workflow/RMfcJExZ0DdXdMnJ/executions/4929|4929> has failed with the following body input:\n```{\n  \"channel_id\": \"C0912AANW1L\",\n  \"channel_name\": \"data-eng-test-ai-channel\",\n  \"conversation_id\": \"C0912AANW1L\",\n  \"event_id\": \"1759517200.009100\",\n  \"event_timestamp\": \"2025-10-03T18:46:40.009Z\",\n  \"is_message_user_bot\": \"False\",\n  \"message_text\": \"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\",\n  \"message_thread_ts\": \"1759516155.914209\",\n  \"message_thread_ts_time\": \"2025-10-03T18:29:15.000Z\",\n  \"message_timestamp\": \"2025-10-03T18:29:15.914Z\",\n  \"message_ts\": \"1759516155.914209\",\n  \"message_user_email\": \"<mailto:pgupta@cribl.io|pgupta@cribl.io>\",\n  \"message_user_first_name\": \"Priya\",\n  \"message_user_id\": \"U02CBV3GSM9\",\n  \"message_user_last_name\": \"Gupta\",\n  \"message_user_name\": \"priya_gupta\",\n  \"reaction\": \"omni\",\n  \"reaction_user_email\": \"<mailto:nkwok@cribl.io|nkwok@cribl.io>\",\n  \"reaction_user_id\": \"U06PVBEK9T6\",\n  \"team_domain\": \"cribl\",\n  \"team_id\": \"T3XQYAF26\",\n  \"thread_conversation_text\": \"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere \\\\n#__--__#\\\\nThe `Slack Error` workflow with execution id <https://n8n-relayer-1.app.n8n.cloud/workflow/RMfcJExZ0DdXdMnJ/executions/4840|4840> has failed with the following body input:\\n```{\\n  \\\"channel_id\\\": \\\"C0912AANW1L\\\",\\n  \\\"channel_name\\\": \\\"data-eng-test-ai-channel\\\",\\n  \\\"conversation_id\\\": \\\"C0912AANW1L\\\",\\n  \\\"event_id\\\": \\\"1759516158.007800\\\",\\n  \\\"event_timestamp\\\": \\\"2025-10-03T18:29:18.007Z\\\",\\n  \\\"is_message_user_bot\\\": \\\"False\\\",\\n  \\\"message_text\\\": \\\"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\\\",\\n  \\\"message_thread_ts\\\": \\\"1759516155.914209\\\",\\n  \\\"message_thread_ts_time\\\": \\\"2025-10-03T18:29:15.000Z\\\",\\n  \\\"message_timestamp\\\": \\\"2025-10-03T18:29:15.914Z\\\",\\n  \\\"message_ts\\\": \\\"1759516155.914209\\\",\\n  \\\"message_user_email\\\": \\\"<mailto:pgupta@cribl.io|pgupta@cribl.io>\\\",\\n  \\\"message_user_first_name\\\": \\\"Priya\\\",\\n  \\\"message_user_id\\\": \\\"U02CBV3GSM9\\\",\\n  \\\"message_user_last_name\\\": \\\"Gupta\\\",\\n  \\\"message_user_name\\\": \\\"priya_gupta\\\",\\n  \\\"reaction\\\": \\\"omni\\\",\\n  \\\"reaction_user_email\\\": \\\"<mailto:pgupta@cribl.io|pgupta@cribl.io>\\\",\\n  \\\"reaction_user_id\\\": \\\"U02CBV3GSM9\\\",\\n  \\\"team_domain\\\": \\\"cribl\\\",\\n  \\\"team_id\\\": \\\"T3XQYAF26\\\",\\n  \\\"thread_conversation_text\\\": \\\"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\\\"\\n}```\"\n}```"},"webhookUrl":"https://n8n-relayer-1.app.n8n.cloud/webhook/8394a134-6af3-4ec0-b605-3270129037cc","executionMode":"production"}}],"Global Vars":[{"json":{"body":{"channel_id":"C0912AANW1L","channel_name":"data-eng-test-ai-channel","conversation_id":"C0912AANW1L","event_id":"1759519800.009800","event_timestamp":"2025-10-03T19:30:00.009Z","is_message_user_bot":"False","message_text":"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere","message_thread_ts":"1759516155.914209","message_thread_ts_time":"2025-10-03T18:29:15.000Z","message_timestamp":"2025-10-03T18:29:15.914Z","message_ts":"1759516155.914209","message_user_email":"pgupta@cribl.io","message_user_first_name":"Priya","message_user_id":"U02CBV3GSM9","message_user_last_name":"Gupta","message_user_name":"priya_gupta","reaction":"omni","reaction_user_email":"nkwok@cribl.io","reaction_user_id":"U06PVBEK9T6","team_domain":"cribl","team_id":"T3XQYAF26","thread_conversation_text":"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere \\n#__--__#\\nThe `Slack Error` workflow with execution id <https://n8n-relayer-1.app.n8n.cloud/workflow/RMfcJExZ0DdXdMnJ/executions/4840|4840> has failed with the following body input:\n```{\n  \"channel_id\": \"C0912AANW1L\",\n  \"channel_name\": \"data-eng-test-ai-channel\",\n  \"conversation_id\": \"C0912AANW1L\",\n  \"event_id\": \"1759516158.007800\",\n  \"event_timestamp\": \"2025-10-03T18:29:18.007Z\",\n  \"is_message_user_bot\": \"False\",\n  \"message_text\": \"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\",\n  \"message_thread_ts\": \"1759516155.914209\",\n  \"message_thread_ts_time\": \"2025-10-03T18:29:15.000Z\",\n  \"message_timestamp\": \"2025-10-03T18:29:15.914Z\",\n  \"message_ts\": \"1759516155.914209\",\n  \"message_user_email\": \"<mailto:pgupta@cribl.io|pgupta@cribl.io>\",\n  \"message_user_first_name\": \"Priya\",\n  \"message_user_id\": \"U02CBV3GSM9\",\n  \"message_user_last_name\": \"Gupta\",\n  \"message_user_name\": \"priya_gupta\",\n  \"reaction\": \"omni\",\n  \"reaction_user_email\": \"<mailto:pgupta@cribl.io|pgupta@cribl.io>\",\n  \"reaction_user_id\": \"U02CBV3GSM9\",\n  \"team_domain\": \"cribl\",\n  \"team_id\": \"T3XQYAF26\",\n  \"thread_conversation_text\": \"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\"\n}``` \\n#__--__#\\nThe `Slack Error` workflow with execution id <https://n8n-relayer-1.app.n8n.cloud/workflow/RMfcJExZ0DdXdMnJ/executions/4929|4929> has failed with the following body input:\n```{\n  \"channel_id\": \"C0912AANW1L\",\n  \"channel_name\": \"data-eng-test-ai-channel\",\n  \"conversation_id\": \"C0912AANW1L\",\n  \"event_id\": \"1759517200.009100\",\n  \"event_timestamp\": \"2025-10-03T18:46:40.009Z\",\n  \"is_message_user_bot\": \"False\",\n  \"message_text\": \"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\",\n  \"message_thread_ts\": \"1759516155.914209\",\n  \"message_thread_ts_time\": \"2025-10-03T18:29:15.000Z\",\n  \"message_timestamp\": \"2025-10-03T18:29:15.914Z\",\n  \"message_ts\": \"1759516155.914209\",\n  \"message_user_email\": \"<mailto:pgupta@cribl.io|pgupta@cribl.io>\",\n  \"message_user_first_name\": \"Priya\",\n  \"message_user_id\": \"U02CBV3GSM9\",\n  \"message_user_last_name\": \"Gupta\",\n  \"message_user_name\": \"priya_gupta\",\n  \"reaction\": \"omni\",\n  \"reaction_user_email\": \"<mailto:nkwok@cribl.io|nkwok@cribl.io>\",\n  \"reaction_user_id\": \"U06PVBEK9T6\",\n  \"team_domain\": \"cribl\",\n  \"team_id\": \"T3XQYAF26\",\n  \"thread_conversation_text\": \"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere \\\\n#__--__#\\\\nThe `Slack Error` workflow with execution id <https://n8n-relayer-1.app.n8n.cloud/workflow/RMfcJExZ0DdXdMnJ/executions/4840|4840> has failed with the following body input:\\n```{\\n  \\\"channel_id\\\": \\\"C0912AANW1L\\\",\\n  \\\"channel_name\\\": \\\"data-eng-test-ai-channel\\\",\\n  \\\"conversation_id\\\": \\\"C0912AANW1L\\\",\\n  \\\"event_id\\\": \\\"1759516158.007800\\\",\\n  \\\"event_timestamp\\\": \\\"2025-10-03T18:29:18.007Z\\\",\\n  \\\"is_message_user_bot\\\": \\\"False\\\",\\n  \\\"message_text\\\": \\\"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\\\",\\n  \\\"message_thread_ts\\\": \\\"1759516155.914209\\\",\\n  \\\"message_thread_ts_time\\\": \\\"2025-10-03T18:29:15.000Z\\\",\\n  \\\"message_timestamp\\\": \\\"2025-10-03T18:29:15.914Z\\\",\\n  \\\"message_ts\\\": \\\"1759516155.914209\\\",\\n  \\\"message_user_email\\\": \\\"<mailto:pgupta@cribl.io|pgupta@cribl.io>\\\",\\n  \\\"message_user_first_name\\\": \\\"Priya\\\",\\n  \\\"message_user_id\\\": \\\"U02CBV3GSM9\\\",\\n  \\\"message_user_last_name\\\": \\\"Gupta\\\",\\n  \\\"message_user_name\\\": \\\"priya_gupta\\\",\\n  \\\"reaction\\\": \\\"omni\\\",\\n  \\\"reaction_user_email\\\": \\\"<mailto:pgupta@cribl.io|pgupta@cribl.io>\\\",\\n  \\\"reaction_user_id\\\": \\\"U02CBV3GSM9\\\",\\n  \\\"team_domain\\\": \\\"cribl\\\",\\n  \\\"team_id\\\": \\\"T3XQYAF26\\\",\\n  \\\"thread_conversation_text\\\": \\\"is there a hircine search that can list all the paying customers ? ie. give me a list of all orgs with an active billing plan , or equivalent query somewhere\\\"\\n}```\"\n}```"},"snowflake_base_url":"https://ml16699-hya89079.snowflakecomputing.com","omni_documents_search_service":{"snowflake_database":"ANALYTICS","snowflake_schema":"OMNI","service_name":"omni_documents_search_service"},"omni_document_queries_query_table_search_service":{"snowflake_database":"ANALYTICS","snowflake_schema":"OMNI","service_name":"omni_document_queries_query_table_search_service"},"omni_document_queries_query_name_search_service":{"snowflake_database":"ANALYTICS","snowflake_schema":"OMNI","service_name":"omni_document_queries_query_name_search_service"},"omni_documents_analyst_agent":{"snowflake_database":"SNOWFLAKE_INTELLIGENCE","snowflake_schema":"AGENTS","agent_name":"OMNI_DOCUMENTS_ANALYST_AGENT"},"omni_document_query_filters_field_name_search_service":{"snowflake_database":"ANALYTICS","snowflake_schema":"OMNI","service_name":"omni_document_query_filters_field_name_search_service"},"zapier_slack_response_webhook":{"webhook_url":"https://hooks.zapier.com/hooks/catch/23046078/u1mp0gx/","direct_message_webhook_url":"https://hooks.zapier.com/hooks/catch/23046078/u90bfmt/"},"slack":{"alerts-data-eng_channel_id":"C06QXJR6V7T","ask-data_channel_id":"C02GRDZS7QF","data-eng-test-ai-channel_channel_id":"C0912AANW1L","zapier_bot_id":"B01304K3N6S","error_message":"The Omni agent could not find relevant dashboards :cry:"},"omni_api":{"omni_base_url":"https://cribl.omniapp.co","model_id":"4345b118-cbbe-4f7c-a705-ea0aa8da57c0","omni_user_id":"8d2bfbb5-8980-4c5c-a6b7-4aad7163acb7"},"snowflake_tables":{"omni_users":{"snowflake_database":"ANALYTICS","snowflake_schema":"OMNI","table_name":"OMNI_USERS"},"omni_documents":{"snowflake_database":"ANALYTICS","snowflake_schema":"OMNI","table_name":"DOCUMENTS"},"omni_document_queries":{"snowflake_database":"ANALYTICS","snowflake_schema":"OMNI","table_name":"DOCUMENT_QUERIES"},"dashboard_recommendations":{"snowflake_database":"RAW","snowflake_schema":"OMNI","table_name":"DASHBOARD_RECOMMENDATIONS_2"},"dashboard_recommendations_feedback":{"snowflake_database":"RAW","snowflake_schema":"OMNI","table_name":"DASHBOARD_RECOMMENDATIONS_FEEDBACK"},"n8n_workflow_executions":{"snowflake_database":"RAW","snowflake_schema":"OMNI","table_name":"N8N_WORKFLOW_EXECUTIONS"}}}}]},"versionId":"60425c3a-1356-45a7-be03-b6cebde0f7cf","triggerCount":1,"shared":[{"updatedAt":"2025-10-07T07:32:02.978Z","createdAt":"2025-10-07T07:32:02.978Z","role":"workflow:owner","workflowId":"1X4HfF4Rou9pBt19","projectId":"2vHf2VxAoKk0WgJE"}],"tags":[]}